#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass IEEEtran
\begin_preamble

%\documentclass[a4paper,10pt]{scrartcl}

\usepackage{amsfonts}\usepackage{amsthm}
\usepackage{float}
\usepackage{hyperref}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithme}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage[usenames]{color}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}




%\title{Dictionary based audio fingerprinting}
%\author{Manuel Moussallam}
%\date{}



\pdfinfo{%
  /Title    (Icassp14_draft)
  /Author   (Manuel Moussallam)
  /Creator  (Manuel Moussallam)
  /Producer ()
  /Subject  ()
  /Keywords ()
}
\end_preamble
\use_default_options false
\maintain_unincluded_children true
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format pdf
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Icassp14_draft"
\pdf_author "Manuel Moussallam"
\pdf_subject "Dictionary Based Audio Fingerprinting"
\pdf_keywords "Sparse Representation"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\branch chapitre1-intro
\selected 1
\filename_suffix 0
\color #ff0000
\end_branch
\branch chapitre2-representation
\selected 1
\filename_suffix 0
\color #005500
\end_branch
\branch chapitre3-MP
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre4-redondances
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre5-structures
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre6-hierarchique
\selected 0
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre7-perspectives
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch AnnexeA
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre-RSSMP
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre-Mpdynamique
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch AnnexeB
\selected 0
\filename_suffix 0
\color #faf0e6
\end_branch
\branch introPartie3
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch resume
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch pageDeGarde
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch Remerciements
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch abstract
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 4cm
\secnumdepth 2
\tocdepth 1
\paragraph_separation indent
\paragraph_indentation default
\quotes_language swedish
\papercolumns 1
\papersides 2
\paperpagestyle default
\bullet 0 1 5 -1
\bullet 1 0 7 -1
\bullet 2 0 8 -1
\tracking_changes false
\output_changes false
\html_math_output 3
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
A General Framework For Dictionary Based Audio Fingerprinting
\end_layout

\begin_layout Author
Manuel Moussallam, Laurent Daudet
\begin_inset Newline newline
\end_inset

Institut Langevin, ESPCI ParisTech - Univ Paris Diderot, 1 rue Jussieu 75005
 Paris, France
\end_layout

\begin_layout Abstract
Our message can be summarized like this: One need a balance between the
 discriminative and the descriptive power of an audio fingerpint.
 The former guarantees good recognition rates, while the latter provides
 robustness.
 State of the art techniques that concentrate on the first (feature-based
 fingerprints, Shazam method etc..) and try to maximize the entropy of the
 fingerprint distribution.
 Techniques concentrated on the second (Cotton and Ellis using MP, Baluja
 using Wavelet Thresholding, etc) experience higher robustness levels but
 have more difficulties to scale up because of a strong biais on their selected
 elements.
 The idea is that audio signals have a strong internal structure, we can
 learn this structure and use it as a probabilistic prior to define an new
 objective function that takes both the descriptive and discriminative power
 into account.
\end_layout

\begin_layout Keywords
Sparse Representation, Audio Fingerprinting
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Standard audio fingerprinting approaches
\end_layout

\begin_layout Standard
Audio objects recognition systems aim at the automatic retrieval of a signal
 
\begin_inset Formula $y$
\end_inset

 among a collection of known sounds objects 
\begin_inset Formula $\{y^{(i)}\}$
\end_inset

.
 In practice, such collection can be very large and sounds are complicated
 objects to compare.
 For this retrieval to be effective, the search must be performed efficiently,
 for instance by comparing low-dimensional 
\emph on
proxies
\emph default
 of the objects, or fingerprints.
\end_layout

\begin_layout Standard
An audio fingerprint is a collection of signal-characteristic features that
 present some robustness to distortions and can be efficiently compared
 to others.
 There are two big families of audio fingerprinting systems, the first one
 adopts a bag of features approach.
 A low-dimensional vector of features (eg.
 Chroma, MFCC, etc..) is thus used as the fingerprint.
 It has essentially been proposed in the Phillips system 
\begin_inset CommandInset citation
LatexCommand cite
key "Haitsma"

\end_inset

 with binarized Chroma.
 A review of such methods can be found in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cano_review"

\end_inset

 and more recent avatars are based on wavelet transforms 
\begin_inset CommandInset citation
LatexCommand cite
key "Baluja2007"

\end_inset

 or finer frequency models 
\begin_inset CommandInset citation
LatexCommand cite
key "Betser_article,Dupraz_article"

\end_inset

.
\end_layout

\begin_layout Standard
The second family of methods is similar in spirit to some feature extraction
 methods developed in image processing (ref vers SIFT?).
 It has first emerged with the work of Wang 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

 and is based on the idea of selecting a subset of 
\emph on
keypoints
\emph default
 in a Time-Frequency representation, pairing them to form 
\emph on
landmarks
\emph default
 and using each of these 
\emph on
landmarks
\emph default
 as an index in a structured database (e.g.
 a hash-table or any fast indexing system).
 This approach gave birth to the well known Shazam system 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang_com"

\end_inset

, but also led to the works of Cotton and Ellis
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

 and Fenet et al 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

 among others.
 While in his seminal work 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

, Wang selected 
\emph on
keypoints
\emph default
 as local maxima in a simple spectrogram, Cotton and Ellis 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

 use a greedy algorithm on a multiscale Gabor dictionary and Fenet 
\emph on
et al
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

 propose a logarithmic transform instead of windowed Fourier.
\end_layout

\begin_layout Standard
All of these methods share a common formalism, that is conveniently exposed
 using a dictionary-based point of view.
 Given a dictionary 
\begin_inset Formula $\Phi$
\end_inset

, one seeks a combination of 
\begin_inset Formula $k$
\end_inset

 elements of 
\begin_inset Formula $\Phi$
\end_inset

 (labeled 
\emph on
atoms
\emph default
) that can be efficiently used as 
\emph on
keypoints
\emph default
 in a fingerprinting system.
 State of the art methods, mainly proposes different dictionaries (e.g.
 Gabor 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang,Wang_com"

\end_inset

, Union of Gabor
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

, MDCT 
\begin_inset CommandInset citation
LatexCommand cite
key "Moussallam2012c"

\end_inset

, Logarithmic 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

..) and selection algorithms (Local Peak Picking 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang,Wang_com,ismir"

\end_inset

, Matching Pursuit 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010,Moussallam2012c"

\end_inset

).
\end_layout

\begin_layout Subsection
A unifying framework
\end_layout

\begin_layout Standard
Quite naturally, one would hope to design a unifying framework for all these
 methods.
 Mainly what distinguish them is the stress that is imposed either on the
 robustness of the landmarks or their discriminative power.
 A robust landmark is one that remain unaltered by distortions such as additive
 noise, compression, time or pitch shifting etc.
 The discriminative power is harder to quantize, but will directly be linked
 to recognition performances.
 A landmark is discriminative when it is highly characteristic of an objects
 fingerprint, that is, it is unlikely to appear in the fingerprint of an
 object that is fairly different.
\end_layout

\begin_layout Standard
Unfortunately, robustness and discriminative power seem to be concurrent
 objectives.
 Indeed, such discriminant information will be found in the high frequencies
 of audio signals, but these frequencies are the most easily altered by
 distortions.
 Additionally, for the search to be efficient, the number of keypoints and
 landmarks must be kept as low as possible.
 
\end_layout

\begin_layout Standard
In this work, we first propose a formulation of the fingerprint design problem
 as a multi-objective optimization of a dictionary-based processing system.
 Then we introduce a proxy of the discriminative power using information
 theoretic tools.
 Using a structured sparsity model for the keypoints (e.g.
 atoms of the dictionary) one can model the probability of selecting a keypoint
 and even the probability of their combinations which allows to use entropy
 measure to characterize the quantity of information carried by a single
 landmark.
 We then propose a general greedy algorithm to build (suboptimal) solutions
 and show that some particular parameter sets corresponds to state of the
 art algorithm described above.
\end_layout

\begin_layout Standard
Finally, we expose on some real scale fingerprint-based recognition experiments,
 that is it possible to reach better points in a pareto diagram, given the
 right knowledge is introduced in the model, mainly by learning the landmark
 distribution parameters on real data.
\end_layout

\begin_layout Section
Dictionary Based Audio Fingerprints
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\boldsymbol{y}\in\mathbb{E}^{N}$
\end_inset

 be a 
\begin_inset Formula $N$
\end_inset

- dimensional discrete signal (
\begin_inset Formula $\boldsymbol{E}=\mathbb{R}$
\end_inset

 or 
\begin_inset Formula $\mathbb{C}$
\end_inset

) and 
\begin_inset Formula $\boldsymbol{\Phi}=\{\phi_{i}\}_{i=1..M}$
\end_inset

 a dictionary of 
\begin_inset Formula $M$
\end_inset

 
\emph on
atoms 
\emph default

\begin_inset Formula $\boldsymbol{\phi}_{i}$
\end_inset

 of same dimension than 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, one speaks of a 
\emph on
representation
\emph default
 
\begin_inset Formula $\hat{y}$
\end_inset

 of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 in 
\begin_inset Formula $\Phi$
\end_inset

 as a linear combinations of the atoms: 
\begin_inset Formula 
\begin{equation}
\hat{y}=\sum_{i=1}^{M}\alpha_{i}\phi_{i}
\end{equation}

\end_inset

where the weights coefficients stacked in an 
\begin_inset Formula $M-$
\end_inset

dimensional vector 
\begin_inset Formula $\boldsymbol{\alpha}$
\end_inset

 now carry the information.
 The nature and quantity of information conveyed by each (or a combination)
 of these 
\begin_inset Formula $\alpha_{i}$
\end_inset

 is entirely determined by how the dictionary is designed and what
\emph on
 a priori 
\emph default
knowledge on the signal is available.
 
\end_layout

\begin_layout Standard
In an audio fingerprint context, it is interesting to further decompose
 
\begin_inset Formula $\boldsymbol{\alpha}$
\end_inset

 as the element-wise product 
\begin_inset Formula $\boldsymbol{\alpha}=\boldsymbol{x}\odot\boldsymbol{s}$
\end_inset

 where 
\begin_inset Formula $x$
\end_inset

 is real or complex valued and 
\begin_inset Formula $\boldsymbol{s}$
\end_inset

 is called the support and restricted to binary values.
 
\begin_inset Formula $s_{i}=$
\end_inset

1 if the atom is selected as a keypoint and zero otherwise.
\end_layout

\begin_layout Subsection
Formalizing fingerprint properties as constraints
\end_layout

\begin_layout Standard
In this formalism, limiting the number of keypoints can be straightforwardly
 transcribed as a sparsity constraint on 
\begin_inset Formula $s$
\end_inset

.
 The robustness property is harder to characterize since different types
 of distortions may occur.
 For the sake of clarity, let us consider only the case of additive white
 Gaussian noise.
 The best way to resist such distortion is to select atoms minimizing a
 reconstruction error.
\end_layout

\begin_layout Standard
More generally, most types of robustness can be enforced by constraints
 of 
\emph on
descriptiveness
\emph default
 of the keypoints.
 Expressing the discriminative power, however, is more challenging.
 This can be done by using information theoretic metrics in general and
 entropy in particular.
 Audio signals often exhibit more energetic low than high-frequencies.
 Corresponding keypoints thus have a higher probability of being selected.
 Intuitively, they provide a less discriminant information on a signal that
 the least probables ones.
 If one is able to fully evaluate the probability distribution of the support
 then one would want to constrain the 
\emph on
entropy
\emph default
 to be the highest possible.
\end_layout

\begin_layout Standard
The problem of finding 
\begin_inset Formula $k$
\end_inset

 keypoints that have maximum descriptive and discriminative potentials can
 thus be stated as :
\begin_inset Formula 
\begin{equation}
\mathcal{P}_{\lambda,k}=\min_{s}\|y-\sum_{i=1}^{M}x_{i}.s_{i}.\phi_{i}\|_{2}-\lambda H_{\Phi}(s)\mbox{ s.t. }\sum_{i=1}^{M}s_{i}=k\label{eq:problem_full}
\end{equation}

\end_inset

here 
\begin_inset Formula $H_{\Phi}(s)$
\end_inset

 is the entropy of the vector 
\begin_inset Formula $s$
\end_inset

 given the dictionary.
\end_layout

\begin_layout Subsection
Probabilistic modeling of the sparse support
\end_layout

\begin_layout Standard
By definition, 
\begin_inset Formula $H_{\Phi}(s)$
\end_inset

 only exists when the probabilistic distribution of 
\begin_inset Formula $s$
\end_inset

 is available.
 Experimentally, one is able to characterize quite efficiently this distribution.
 Let 
\begin_inset Formula $\Phi$
\end_inset

 be a time-frequency dictionary, and let us observe the solutions to 
\begin_inset Formula $\mathcal{P}_{0,k}$
\end_inset

, that is the sparse reconstruction problem without entropic constraint.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Empirical-Biais"

\end_inset

 displays the empirical distribution of keypoints selected with a algorithm
 from the Matching Pursuit (MP 
\begin_inset CommandInset citation
LatexCommand cite
key "Mallat_TSP1993"

\end_inset

) family as in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010,Moussallam2012c"

\end_inset

.
 The dictionary is a union of 7 MDCT scales replicated such as to form a
 highly overcomplete shift-invariant dictionary.
 Atoms are uniformly selected in time while a strong biais on their frequency
 localization can be observed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/All100Atoms_GTZAN_100files_7xMDCT.png
	lyxscale 20
	width 8cm

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Empirical distribution of the first 100 atoms observed on 600 audio segments
 of 4 seconds each, taken from the GTZAN dataset.
 Signals are downsampled to 8KHz, are of size 
\begin_inset Formula $N=32000$
\end_inset

, the highly overcomplete dictionary is made of roughly 65 millions atoms.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Empirical-Biais"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/empirical_cooc_mat_GTZAN_20files_100atoms_3xMDCT.png
	lyxscale 25
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Empirical Co-occurrence matrix (sparse pattern)
\begin_inset CommandInset label
LatexCommand label
name "fig:Empirical-Covariance"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
At en even deeper level, one can empirically observe the covariance matrix
 of the support.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Empirical-Covariance"

\end_inset

 shows the sparsity pattern of such matrix for a union of 3 MDCT scales
 of length 8, 64 and 512ms.
 Strong correlations can be observed that can be grouped in two categories:
\end_layout

\begin_layout Itemize
Neighborhood correlations: keypoints close to each other in the time-frequency
 plane are often jointly selected.
\end_layout

\begin_layout Itemize
Harmonic correlations: in the larger scale, keypoints on harmonic frequencies
 also have a higher probability of joint appearance.
\end_layout

\begin_layout Standard
This basically tells us that landmarks build on neighboring and harmonically
 related keypoints are less informative (i.e.
 discriminative) than others.
\end_layout

\begin_layout Standard
Problem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:problem_full"

\end_inset

 is, in general, NP-hard to solve.
 The literature can be understood as suboptimal methods to adress this problem:
\end_layout

\begin_layout Itemize
The Shazam system 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang_com"

\end_inset

 and its extensions 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

, never explicitly expresses the entropic constraint.
 However, their strategy is to ensure the selected keypoints are spread
 all over the time-frequency plane.
 Basically, this amounts to forbidding the construction of landmarks from
 neighboring keypoints which are the less discriminative.
 Overall, the local peak-picking strategy can be understood as an entropy-orient
ed strategy and can lead to robustness issues.
\end_layout

\begin_layout Itemize
Systems such as the one proposed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

 put all the emphasis on the robustness to distortions.
 Their landmarks are tailored for retrieval of highly distorted objects,
 but it might be at the expense of their discriminativeness.
\end_layout

\begin_layout Standard
Finally, let us draw a parallel with some fingerprinting techniques such
 as the Distortion Discriminant Analysis exposed by Burges 
\emph on
et al
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Burges2003"

\end_inset

, to our knowledge, would also fit in this framework but with a dictionary
 learning paradigm.
\end_layout

\begin_layout Section
Proposed Framework
\end_layout

\begin_layout Subsection
Structured Sparsity model
\end_layout

\begin_layout Standard
Empirical evidence suggest the sparsity pattern of the support vector in
 time-frequency dictionaries is highly structured.
 Boltzmann machines seem to be the most expressive model for the distribution
 of 
\begin_inset Formula $s$
\end_inset

.
 
\begin_inset Formula 
\begin{equation}
p(s)\propto\exp(b^{T}s+s^{T}Ws)
\end{equation}

\end_inset

This distribution has first been proposed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Hinton1986"

\end_inset

.
 It models the interaction in a graph of connected nodes (keypoints in our
 case) using two parameters: a biais 
\begin_inset Formula $b$
\end_inset

 and a connectivity matrix 
\begin_inset Formula $W$
\end_inset

.
 This model has recently appeared in dictionary based processing setups.
 Dremeau 
\emph on
et al
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Dremeau2012"

\end_inset

 show that it generalizes many structured sparsity models.
 More importantly, we can evaluate the probability of a state using the
 difference of energy at node 
\begin_inset Formula $i$
\end_inset

:
\begin_inset Formula 
\begin{equation}
\Delta E_{i}=\sum_{j}w_{ij}+b_{i}
\end{equation}

\end_inset

and the notion of temperature 
\begin_inset Formula $T$
\end_inset

 that can be dropped out (e.g.
 
\begin_inset Formula $T=1$
\end_inset

).
 Fixing the states of all other variables, the probability of node 
\begin_inset Formula $i$
\end_inset

 being turned on (i.e.
 keypoint 
\begin_inset Formula $i$
\end_inset

 being selected) writes: 
\begin_inset Formula 
\begin{equation}
p(s_{i}=1|\{s_{j\neq i}\})=\frac{1}{1+\exp\left(-\Delta E_{i}\right)}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Reducing model complexity
\end_layout

\begin_layout Standard
The expressiveness of the Boltzmann machine is essentially captured by the
 
\begin_inset Formula $W$
\end_inset

 matrix which is of size 
\begin_inset Formula $M\times M$
\end_inset

 where 
\begin_inset Formula $M$
\end_inset

 is the number of atoms in the dictionary.
 Clearly, for real scale data, the resulting model complexity will become
 prohibitive.
 Fortunately, the considered dictionaries are further structured.
 Let assume each atom 
\begin_inset Formula $\phi_{i}$
\end_inset

 can be indexed by a unique triplet 
\begin_inset Formula $(f_{i},t_{i},l_{i})\in\mathcal{F}\times\mathcal{T}\times\mathcal{L}$
\end_inset

 of its frequency and time centroids and length.
 A way to drastically reduce the complexity is to assume separability of
 the time and frequency centroids variables.
 Such hypothesis seem reasonable, keypoints frequency localization will
 essentially be linked to other keypoints frequencies and lengths, independently
 of their time position.
 Symmetrically, time localizations may be considered apart from the frequency
 localization.
\end_layout

\begin_layout Standard
In practice, this implies cutting many vertices in the Boltzmann machine,
 or equivalently putting many elements of 
\begin_inset Formula $W$
\end_inset

 to zero.
 The biais can be rewritten as :
\begin_inset Formula 
\begin{equation}
b_{i}=b(f_{i},t_{i},l_{i})=b(f_{i},l_{i})
\end{equation}

\end_inset

since we have seen empirically that keypoints are uniformly located in time.
 Similarly, each element 
\begin_inset Formula $w_{ij}$
\end_inset

 of the 
\begin_inset Formula $W$
\end_inset

 matrix can be expressed as a product:
\begin_inset Formula 
\begin{eqnarray*}
w_{ij} & = & w\left[\left(f_{i},t_{i},l_{i}\right)\left(f_{j},t_{j},l_{j}\right)\right]\\
 & = & w^{F}\left[\left(f_{i},l_{i}\right)\left(f_{j},l_{j}\right)\right]w^{T}\left[\left(t_{i},l_{i}\right)\left(t_{j},l_{j}\right)\right]\\
 & = & w_{ij}^{F}w_{ij}^{T}
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $w_{ij}^{F}\mbox{ and }w_{ij}^{T}$
\end_inset

 are taken in two factoring matrices 
\begin_inset Formula $W_{F}$
\end_inset

 and 
\begin_inset Formula $W_{T}$
\end_inset

.
\end_layout

\begin_layout Standard
TODO: nice plotting of synthetic W matrices and Real ones learned as expectation
 over training samples.
 The pluri-diagonal model expresses neighboring correlations while sub-diagonals
 in Wf show the harmonic relationships.
\end_layout

\begin_layout Subsection
Algorithm
\end_layout

\begin_layout Standard
Addressing problem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:problem_full"

\end_inset

 is a complicated issue.
 Indeed, even with 
\begin_inset Formula $\lambda=0$
\end_inset

, it requires either a relaxation of the sparsity constraint or the use
 of suboptimal greedy algorithms such as MP.
 Given that the hard sparsity constraint is strict in this case, we have
 chosen to modify an MP algorithm by simply changing the atom selection
 rule.
 
\end_layout

\begin_layout Standard
Such algorithm makes a series of local decisions (i.e.
 keypoint selection), based only on the knowledge of the previous choices
 (i.e.
 which keypoints have already been selected).
 The residual signal 
\begin_inset Formula $r^{n}$
\end_inset

 is usually updated by subtracting from the original signal its projection
 on the subspace spanned by the selected atoms.
 At iteration 
\begin_inset Formula $n$
\end_inset

 the decision boils down to solving:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\arg\max_{\phi}|\langle r^{n},\phi_{i}\rangle|(1+\lambda_{H}H(\phi_{i}|s_{n-1}))
\end{equation}

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $H(\phi_{i}|s_{n-1})$
\end_inset

 is the
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 entropy of choosing atom 
\begin_inset Formula $\phi_{i}$
\end_inset

 knowing the support 
\begin_inset Formula $s_{n-1}$
\end_inset

 and writes: 
\begin_inset Formula 
\begin{eqnarray}
H(\phi_{i}|s_{n-1}) & = & -p(\phi_{i}|s_{n-1})\log\left[p(\phi_{i}|s_{n-1})\right]\nonumber \\
 & = & \frac{\log\left[1+\sum_{j\in\Gamma_{n-1}}w_{ij}+b_{i}\right]}{1+\sum_{j\in\Gamma_{n-1}}w_{ij}+b_{i}}
\end{eqnarray}

\end_inset

with 
\begin_inset Formula $\Gamma_{n-1}$
\end_inset

 being the indices of the non zero elements of 
\begin_inset Formula $s_{n-1}$
\end_inset

, or the keypoints selected so far.
 An advantage of this algorithm is that it can be quickly implemented with
 existing TF-based MP libraries such as PyMP
\begin_inset Foot
status open

\begin_layout Plain Layout
https://github.com/mmoussallam/PyMP
\end_layout

\end_inset

.
 Another advantage is the special case 
\begin_inset Formula $\lambda_{H}=0$
\end_inset

 exactly corresponds to the Cotton and Ellis method, while with proper choice
 of the 
\begin_inset Formula $W$
\end_inset

 matrix, the case 
\begin_inset Formula $\lambda_{H}=\infty$
\end_inset

 is very close to the Shazam framework.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/KeyPoints_and_pairs.pdf
	width 16cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Visualization
\emph on
 
\emph default
of the TF 
\emph on
landmarks
\emph default
 built by the algorithm.
 From left to right 
\begin_inset Formula $\lambda_{H}=0$
\end_inset

 (similar to 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

), 
\begin_inset Formula $\lambda_{H}=10$
\end_inset

 and 
\begin_inset Formula $\lambda_{H}=\infty$
\end_inset

 (similar to 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Standard
In this study we're interested in the object recognition problem which is
 a particular audio fingerprint case.
 Given a database of sounds, we want to be able to quickly find an object
 in it.
 Binary Metric: is it rightfully located or not.
 Parameters: 1) size of base (number of keys) 2) computation time.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/robustness_7snrs_600segs_2tests_30sparsity.pdf
	width 6cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Robustness results with synthetic 
\begin_inset Formula $W$
\end_inset

 and varying 
\begin_inset Formula $\lambda_{H}$
\end_inset

.
 The proportion of identical landmarks is averaged over 5 trials of random
 Gaussian noise on each of 600 random segments of 5 seconds taken in the
 GTZAN dataset.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
So we must see how the modified criterion affects the recognition rate and
 robustness.
 We can compare to Shazam [Wang2003], [Cotton/Ellis2010] (pairs of MP atoms)
 and [Fenet/Moussallam2012] (single MP atoms).
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Standard
Using a dictionary-based framework, we can efficiently characterize the
 concurrent objectives that a recognition system must deal with.
 The problem can be stated as: how to select a sparse set of elements that
 are effective at describing my signal (e.g.
 reconstruct it) and allow me to discriminate it from others.
 State of the art methods appears to be extremum points on a pareto front,
 we propose a greedy algorithm to reach other points on this front.
 There is further work to be done with the structured sparsity model, especially
 one could try a much more global optimization by using Bayesian versions
 of the MP
\begin_inset CommandInset citation
LatexCommand cite
key "Dremeau2012"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "ICASSP14"
options "ieeetr"

\end_inset


\end_layout

\end_body
\end_document
