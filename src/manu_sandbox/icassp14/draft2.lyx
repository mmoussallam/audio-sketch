#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass IEEEtran
\begin_preamble

%\documentclass[a4paper,10pt]{scrartcl}

\usepackage{amsfonts}\usepackage{amsthm}
\usepackage{float}
\usepackage{hyperref}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithme}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage[usenames]{color}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}




%\title{Dictionary based audio fingerprinting}
%\author{Manuel Moussallam}
%\date{}



\pdfinfo{%
  /Title    (Icassp14_draft)
  /Author   (Manuel Moussallam)
  /Creator  (Manuel Moussallam)
  /Producer ()
  /Subject  ()
  /Keywords ()
}
\end_preamble
\use_default_options false
\maintain_unincluded_children true
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format pdf
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Icassp14_draft"
\pdf_author "Manuel Moussallam"
\pdf_subject "Dictionary Based Audio Fingerprinting"
\pdf_keywords "Sparse Representation"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\branch chapitre1-intro
\selected 1
\filename_suffix 0
\color #ff0000
\end_branch
\branch chapitre2-representation
\selected 1
\filename_suffix 0
\color #005500
\end_branch
\branch chapitre3-MP
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre4-redondances
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre5-structures
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre6-hierarchique
\selected 0
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre7-perspectives
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch AnnexeA
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre-RSSMP
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch chapitre-Mpdynamique
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch AnnexeB
\selected 0
\filename_suffix 0
\color #faf0e6
\end_branch
\branch introPartie3
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch resume
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch pageDeGarde
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch Remerciements
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch abstract
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 4cm
\secnumdepth 2
\tocdepth 1
\paragraph_separation indent
\paragraph_indentation default
\quotes_language swedish
\papercolumns 1
\papersides 2
\paperpagestyle default
\bullet 0 1 5 -1
\bullet 1 0 7 -1
\bullet 2 0 8 -1
\tracking_changes false
\output_changes false
\html_math_output 3
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
A General Framework For Dictionary Based Audio Fingerprinting
\end_layout

\begin_layout Author
Manuel Moussallam, Laurent Daudet
\begin_inset Newline newline
\end_inset

Institut Langevin, ESPCI ParisTech - Univ Paris Diderot, 1 rue Jussieu 75005
 Paris, France
\end_layout

\begin_layout Abstract
Our message can be summarized like this: One need a balance between the
 discriminative and the descriptive power of an audio fingerpint.
 The former guarantees good recognition rates, while the latter provides
 robustness.
 State of the art techniques that concentrate on the first (feature-based
 fingerprints, Shazam method etc..) and try to maximize the entropy of the
 fingerprint distribution.
 Techniques concentrated on the second (Cotton and Ellis using MP, Baluja
 using Wavelet Thresholding, etc) experience higher robustness levels but
 have more difficulties to scale up because of a strong biais on their selected
 elements.
 The idea is that audio signals have a strong internal structure, we can
 learn this structure and use it as a probabilistic prior to define an new
 objective function that takes both the descriptive and discriminative power
 into account.
\end_layout

\begin_layout Keywords
Sparse Representation, Audio Fingerprinting
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Standard audio fingerprinting approaches
\end_layout

\begin_layout Standard
Audio objects recognition systems aim at the automatic retrieval of a signal
 
\begin_inset Formula $y$
\end_inset

 among a collection of known sounds objects 
\begin_inset Formula $\{y^{(i)}\}$
\end_inset

.
 In practice, such collection can be very large and sounds are complicated
 objects to compare.
 For this retrieval to be effective, the search must be performed efficiently,
 for instance by comparing low-dimensional 
\emph on
proxies
\emph default
 of the objects, or fingerprints.
\end_layout

\begin_layout Standard
An audio fingerprint is a collection of signal-characteristic features that
 present some robustness to distortions and can be efficiently compared
 to others.
 There are two big families of audio fingerprinting systems, the first one
 adopts a bag of features approach.
 A low-dimensional vector of features (eg.
 Chroma, MFCC, etc..) is thus used as the fingerprint.
 It has essentially been proposed in the Phillips system 
\begin_inset CommandInset citation
LatexCommand cite
key "Haitsma"

\end_inset

 with binarized Chroma.
 A review of such methods can be found in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cano_review"

\end_inset

 and more recent avatars are based on finer frequency models 
\begin_inset CommandInset citation
LatexCommand cite
key "Betser_article,Dupraz_article"

\end_inset

.
\end_layout

\begin_layout Standard
The second family of methods is similar in spirit to some feature extraction
 methods developed in image processing (ref vers SIFT?).
 It has first emerged with the work of Wang 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

 and is based on the idea of selecting a subset of 
\emph on
keypoints
\emph default
 in a Time-Frequency representation, pairing them to form 
\emph on
landmarks
\emph default
 and using each of these 
\emph on
landmarks
\emph default
 as an index in a structured database (e.g.
 a hash-table or any fast indexing system).
 This approach gave birth to the well known Shazam system 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang_com"

\end_inset

, but also led to the works of Baluja
\begin_inset CommandInset citation
LatexCommand cite
key "Baluja2007"

\end_inset

, Cotton and Ellis
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

 among others.
 While in his seminal work 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

, Wang selected 
\emph on
keypoints
\emph default
 as local maxima in a simple spectrogram, Baluja proposes to threshold wavelets
 coefficients, Cotton and Ellis 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

 use a greedy algorithm on a multiscale Gabor dictionary and Fenet 
\emph on
et al
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

 propose a logarithmic transform instead of windowed Fourier.
\end_layout

\begin_layout Standard
All of these methods share a common formalism, that is conveniently exposed
 using a dictionary-based point of view.
 Given a dictionary 
\begin_inset Formula $\Phi$
\end_inset

, one seeks a combination of 
\begin_inset Formula $k$
\end_inset

 elements of 
\begin_inset Formula $\Phi$
\end_inset

 (labeled 
\emph on
atoms
\emph default
) that can be efficiently used as 
\emph on
keypoints
\emph default
 in a fingerprinting system.
 State of the art methods, mainly proposes different dictionaries (e.g.
 Gabor 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang,Wang_com"

\end_inset

, Wavelets
\begin_inset CommandInset citation
LatexCommand cite
key "Baluja2007"

\end_inset

, Union of Gabor
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

, MDCT 
\begin_inset CommandInset citation
LatexCommand cite
key "Moussallam2012c"

\end_inset

, Logarithmic 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

..) and selection algorithms (Local Peak Picking 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang,Wang_com,ismir"

\end_inset

, Thresholding 
\begin_inset CommandInset citation
LatexCommand cite
key "Baluja2007"

\end_inset

, Matching Pursuit 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010,Moussallam2012c"

\end_inset

).
\end_layout

\begin_layout Subsection
A unifying framework
\end_layout

\begin_layout Standard
Quite naturally, one would hope to design a unifying framework for all these
 methods.
 Mainly what distinguish them is the stress that is imposed either on the
 robustness of the landmarks or their discriminative power.
 A robust landmark is one that remain unaltered by distortions such as additive
 noise, compression, time or pitch shifting etc.
 The discriminative power is harder to quantize, but will directly be linked
 to recognition performances.
 A landmark is discriminative when it is highly characteristic of an objects
 fingerprint, that is, it is unlikely to appear in the fingerprint of an
 object that is fairly different.
\end_layout

\begin_layout Standard
Unfortunately, robustness and discriminative power seem to be concurrent
 objectives.
 Indeed, such discriminant information will be found in the high frequencies
 of audio signals, but these frequencies are the most easily altered by
 distortions.
 Additionally, for the search to be efficient, the number of keypoints and
 landmarks must be kept as low as possible.
 
\end_layout

\begin_layout Standard
In this work, we first propose a formulation of the fingerprint design problem
 as a multi-objective optimization of a dictionary-based processing system.
 Then we introduce a proxy of the discriminative power using information
 theoretic tools.
 Using a structured sparsity model for the keypoints (e.g.
 atoms of the dictionary) one can model the probability of selecting a keypoint
 and even the probability of their combinations which allows to use entropy
 measure to characterize the quantity of information carried by a single
 landmark.
 We then propose a general greedy algorithm to build (suboptimal) solutions
 and show that some particular parameter sets corresponds to state of the
 art algorithm described above.
\end_layout

\begin_layout Standard
Finally, we expose on some real scale fingerprint-based recognition experiments,
 that is it possible to reach better points in a pareto diagram, given the
 right knowledge is introduced in the model, mainly by learning the landmark
 distribution parameters on real data.
\end_layout

\begin_layout Section
Dictionary Based Audio Fingerprints
\end_layout

\begin_layout Subsection
Problem statement
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\boldsymbol{y}\in\mathbb{E}^{N}$
\end_inset

 be a 
\begin_inset Formula $N$
\end_inset

- dimensional discrete signal (
\begin_inset Formula $\boldsymbol{E}=\mathbb{R}$
\end_inset

 or 
\begin_inset Formula $\mathbb{C}$
\end_inset

) and 
\begin_inset Formula $\boldsymbol{\Phi}=\{\phi_{i}\}_{i=1..M}$
\end_inset

 a dictionary of 
\begin_inset Formula $M$
\end_inset

 
\emph on
atoms 
\emph default

\begin_inset Formula $\boldsymbol{\phi}_{i}$
\end_inset

 of same dimension than 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, one speaks of a 
\emph on
representation
\emph default
 
\begin_inset Formula $\hat{y}$
\end_inset

 of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 in 
\begin_inset Formula $\Phi$
\end_inset

 as a linear combinations of the atoms: 
\begin_inset Formula 
\begin{equation}
\hat{y}=\sum_{i=1}^{M}\alpha_{i}\phi_{i}
\end{equation}

\end_inset

where the weights coefficients stacked in an 
\begin_inset Formula $M-$
\end_inset

dimensional vector 
\begin_inset Formula $\boldsymbol{\alpha}$
\end_inset

 now carry the information.
 The nature and quantity of information conveyed by each (or a combination)
 of these 
\begin_inset Formula $\alpha_{i}$
\end_inset

 is entirely determined by how the dictionary is designed and what
\emph on
 a priori 
\emph default
knowledge on the signal is available.
 
\end_layout

\begin_layout Standard
In an audio fingerprint context, it is interesting to further decompose
 
\begin_inset Formula $\boldsymbol{\alpha}$
\end_inset

 as the element-wise product 
\begin_inset Formula $\boldsymbol{\alpha}=\boldsymbol{x}\odot\boldsymbol{s}$
\end_inset

 where 
\begin_inset Formula $x$
\end_inset

 is real or complex valued and 
\begin_inset Formula $\boldsymbol{s}$
\end_inset

 is called the support and restricted to binary values.
 
\begin_inset Formula $s_{i}=$
\end_inset

1 if the atom is selected as a keypoint and zero otherwise.
\end_layout

\begin_layout Paragraph
Formalizing fingerprint properties as constraints
\end_layout

\begin_layout Standard
In this formalism, limiting the number of keypoints can be straightforwardly
 transcribed as a sparsity constraint on 
\begin_inset Formula $s$
\end_inset

.
 The robustness property is harder to characterize since different types
 of distortions may occur.
 For the sake of clarity, let us consider only the case of additive white
 Gaussian noise.
 The best way to resist such distortion is to select atoms minimizing a
 reconstruction error.
\end_layout

\begin_layout Standard
More generally, most types of robustness can be enforced by constraints
 of 
\emph on
descriptiveness
\emph default
 of the keypoints.
 Expressing the discriminative power, however, is more challenging.
 This can be done by using information theoretic metrics in general and
 entropy in particular.
 Figure 1 displays the empirical distribution of keypoints selected with
 C10 algorithm in the Time-Frequency plane.
 Clearly, low-frequency points have a much higher probability of being selected.
 Intuitively, they provide a less discriminant information on a signal that
 the least probables ones.
 If one is able to fully evaluate the probability distribution of the support
 then one would want to constrain the entropy to be the highest possible.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/All100Atoms_GTZAN_100files_7xMDCT.png
	lyxscale 20
	width 8cm

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Empirical distribution of the first 100 atoms observed on 600 audio segments
 of 5 seconds each taken from the GTZAN dataset.
 The dictionary is a union of 7 MDCT scales replicated such as to form a
 highly overcomplete shift-invariant dictionary.
 Atoms are uniformly selected in time while a strong biais on frequencies
 can be observed.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The problem of finding 
\begin_inset Formula $k$
\end_inset

 keypoints that have maximum descriptive and discriminative potentials can
 be stated as :
\begin_inset Formula 
\begin{equation}
\min_{s}\|y-\sum_{i=1}^{M}x_{i}\cdot s_{i}\cdot\phi_{i}\|_{2}-\lambda H_{\Phi}(s)\mbox{ s.t. }\sum_{i=1}^{M}s_{i}=k
\end{equation}

\end_inset

here 
\begin_inset Formula $H_{\Phi}(s)$
\end_inset

 is the entropy of the vector 
\begin_inset Formula $s$
\end_inset

 given the dictionary.
\end_layout

\begin_layout Subsection
State of the art techniques
\end_layout

\begin_layout Standard
This is NP hard, the literature can be understood as suboptimal algorithm
 on this problem:
\end_layout

\begin_layout Itemize
Shazam: ad-hoc method to maximize the entropy
\end_layout

\begin_layout Itemize
Cotton, Baluja, Moussallam: no entropy penalty: all on robustness
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/empirical_cooc_mat_GTZAN_20files_100atoms_3xMDCT.png
	lyxscale 25
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Empirical Co-occurrence matrix (sparse pattern)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Proposed Framework
\end_layout

\begin_layout Subsection
Structured Sparsity model
\end_layout

\begin_layout Standard
Using a Boltzmann machine as the distribution of the support:
\begin_inset Formula 
\[
p(s)\propto\exp(b^{T}s+s^{T}Ws)
\]

\end_inset

This model seems fitted for our case since we can experimentally observe
 both the biais 
\begin_inset Formula $b$
\end_inset

 and the interaction between atoms captured in the 
\begin_inset Formula $W$
\end_inset

 matrix.
 More importantly, we can evaluate the probability of an atoms state using
 the difference of energy:
\begin_inset Formula 
\[
\Delta E_{i}=\sum_{j}w_{ij}+b_{i}
\]

\end_inset

and the notion of Temperature 
\begin_inset Formula $T$
\end_inset

 that can be dropped out for now.
\begin_inset Formula 
\[
p(s_{i}=1)=\frac{1}{1+\exp\left(\frac{-\Delta E_{i}}{T}\right)}
\]

\end_inset

in our case however, we are going to have a simpler expression since we
 are going to assume that we know the state of all the others units.
 Indeed, at iteration 
\begin_inset Formula $n$
\end_inset

 we know the set 
\begin_inset Formula $\Gamma^{n}$
\end_inset

 of already selected atom.
 A probability can thus be 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(s_{i}=1)=\frac{1}{1+\exp\left[-\left(\sum_{j\in\Gamma^{n}}w_{ij}+b_{i}\right)\right]}
\]

\end_inset


\end_layout

\begin_layout Standard
with 
\begin_inset Formula $b$
\end_inset

 being a biais and 
\begin_inset Formula $W$
\end_inset

 a correlation matrix between an atom and the others.
 To go a little further, an TF atom can be indexed by a triplet 
\begin_inset Formula $(f,t,l)$
\end_inset

 of its frequency, time localization and length.
 For the biais, we are going to assume separability of 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

 marginalized over the scale:
\begin_inset Formula 
\begin{eqnarray*}
p(f,t,l) & = & p(f,t|l)p(l)\\
 & = & p(f|l)p(t|l)p(l)
\end{eqnarray*}

\end_inset

 then we have a standard model for 
\begin_inset Formula $p(l)$
\end_inset

 and we set Boltzmann machines on the marginal distributions
\begin_inset Formula 
\[
p(f,|l)\propto\exp(b_{f}s+sW_{f}s)
\]

\end_inset


\end_layout

\begin_layout Subsection
Model Learning
\end_layout

\begin_layout Standard
We will use Hebbian learning in this context, which means given a training
 set we can compute empirical averages for 
\begin_inset Formula $b$
\end_inset

 and 
\begin_inset Formula $W$
\end_inset

.
 Here I will provide nice pictures of how the atoms are pairwise correlated
 in a multiscale TF dictionary as well as proving that the biais is only
 visible on the frequency and scale parameters (atoms are uniformly located
 in time, which by the way justifies to get rid of the absolute time information
 in the fingerprint key).
\end_layout

\begin_layout Subsection
Algorithm
\end_layout

\begin_layout Standard
A standard MP with a modified selection rule specifying:
\begin_inset Formula 
\[
\arg\max_{\phi}|\langle r^{n},\phi_{i}\rangle|(1+\lambda_{H}H(\phi_{i}|s_{n-1}))
\]

\end_inset

with 
\begin_inset Formula $p(\phi_{i}|s_{n-1})=b_{i}+\sum_{j\in\Gamma^{n-1}}w_{ij}$
\end_inset

 where 
\begin_inset Formula $b_{i}$
\end_inset

 is the biais of the atom 
\begin_inset Formula $\phi_{i}$
\end_inset

 and the second term simply add up the pairwise codependency of an atom
 with all the previously selected ones.
 A nice property is that this second term is quite simple to update:
\begin_inset Formula 
\begin{eqnarray*}
H(\phi_{i}|s_{n}) & = & -p(\phi_{i}|s_{n})\log\left[p(\phi_{i}|s_{n})\right]\\
 & = & -\left(p(\phi_{i}|s_{n-1})+w_{ij^{\star}}\right)\log\left[p(\phi_{i}|s_{n-1})+w_{ij^{\star}}\right]
\end{eqnarray*}

\end_inset

with 
\begin_inset Formula $j^{\star}$
\end_inset

 being the index of the atom just selected.
\end_layout

\begin_layout Subsection
Particular cases
\end_layout

\begin_layout Standard
A particular case is of course when 
\begin_inset Formula $\lambda_{H}$
\end_inset

 is set to zero, we come back to the Cotton2010 algorithm.
 In order to get Wang2003 results, what ca we do? we can put 
\begin_inset Formula $\infty$
\end_inset

 in neighborhood cells of the 
\begin_inset Formula $W$
\end_inset

 matrix which basically will prevent the selection of atoms in the direct
 neighborhood.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/KeyPoints_and_pairs.pdf
	width 16cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Keypoints and pairs built with Wang03, Cotton10 and Ours 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Standard
In this study we're interested in the object recognition problem which is
 a particular audio fingerprint case.
 Given a database of sounds, we want to be able to quickly find an object
 in it.
 Binary Metric: is it rightfully located or not.
 Parameters: 1) size of base (number of keys) 2) computation time.
\end_layout

\begin_layout Standard
So we must see how the modified criterion affects the recognition rate and
 robustness.
 We can compare to Shazam [Wang2003], [Cotton/Ellis2010] (pairs of MP atoms)
 and [Fenet/Moussallam2012] (single MP atoms).
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
Using a dictionary-based framework, we can efficiently characterize the
 concurrent objectives that a recognition system must deal with.
 The problem can be stated as: how to select a sparse set of elements that
 are effective at describing my signal (e.g.
 reconstruct it) and allow me to discriminate it from others.
 State of the art methods appears to be extremum points on a pareto front,
 we propose a greedy algorithm to reach other points on this front.
 There is further work to be done with the structured sparsity model, especially
 one could try a much more global optimization by using Bayesian versions
 of the MP
\begin_inset CommandInset citation
LatexCommand cite
key "Dremeau2012"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "ICASSP14"
options "ieeetr"

\end_inset


\end_layout

\end_body
\end_document
