#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 3cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Technical report - september 2013
\end_layout

\begin_layout Author
M.
 Moussallam
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Context of this study
\end_layout

\begin_layout Standard
This document summarizes the technical details of the framework built as
 part of the Sketch 2 (a.k.a.
 Ghost Sounds) project.
 More precisely, it is part of the work-packages (WP) 1.1 and 1.2.
 For the sake of readability and clarity, the amount of technical details
 is limited to what is necessary for apprehending the basics concepts.
\end_layout

\begin_layout Subsection*
Goals and Tasks
\end_layout

\begin_layout Standard
The first phase of the project aims at building a 
\begin_inset Quotes eld
\end_inset

sketchifying
\begin_inset Quotes erd
\end_inset

 process tailored for priming experiments.
 The deliverable should take the form of a reusable piece of software that
 is able to build a 
\begin_inset Quotes eld
\end_inset

sketch
\begin_inset Quotes erd
\end_inset

 from any given audio scene.
\end_layout

\begin_layout Itemize
WP 1.1 consists in the definition and characterization of audio 
\begin_inset Quotes eld
\end_inset

sketches
\begin_inset Quotes erd
\end_inset

 via a signal and/or a statistical model.
 We are interested in finding not only the main features of sounds, but
 more importantly their peculiar ones.
 In order to do so, one must first decide of a feature space on which to
 project the signals, and second, distinguish which of these feature (or
 sets of features) are discriminative.
\end_layout

\begin_layout Itemize
WP 1.2 addresses the problem of validation via an automatic recognition task.
 The recognition is performed by means of acoustic fingerprints comparison.
 This research field being a mature one, the objective can not be to compete
 with existing industrial solution.
 Nonetheless, those should serve as a basis for benchmarking any proposed
 fingerprint scheme.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
The goal of this task is to build a sketches model for a specific class
 of sounds under study (for instance in the statistics of selected features,
 and maybe more importantly in their pairwise correlation).
 From this model and a given sound, we can now investigate how can we build
 a sound “fingerprint” that is as compact as possible, and that uniquely
 identifies this sound.
 From an information theory standpoint, the selected features would not
 be the ones that simply best describe the sound, but the ones that best
 describe the sound knowing the sound model, in other words the features
 that distinguish the individual from the group.
 To come back to the original visual metaphor, we do not desire a realistic
 “sketch” anymore, but a voluntarily distorted “caricature” that emphasizes
 the specifics of the original object and forgets about features that may
 be large in absolute terms but in standard proportion in the average model
 (when we want to describe a person’s face, we do not start by saying “he
 has a mouth, a nose and two eyes”, as these are important but obvious features,
 we only focus on small specific details “he has a square chin and large
 ears”).
 Fundamentally speaking, this can be seen as a generalized notion of sound
 timbre, not as an instrinsic quality of the sound, but as a notion relative
 to the other sounds (the original notion of timbre is the set of characteristic
s that allow us to distinguish two sounds that have the same pitch, duration,
 and loudness).
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Object and concept definitions
\end_layout

\begin_layout Description
Sounds Any digital audio signal, as the discrete sampling of an acoustic
 wave.
 For simplicity's sake, the spatial properties may be discarded and only
 mono-channel signals may be considered.
 Among properties one may find the sampling frequency and the length or
 duration.
\end_layout

\begin_layout Description
Track An audio track is a long sound (in the order of 30 seconds to several
 minutes) that may for instance be a musical interpretation.
 Among properties one may find the title, artist name, duration, musical
 genre or speaker id.
\end_layout

\begin_layout Description
Scene An audio scene is a short sound, e.g.
 a single sentence uttered by a speaker or an environmental sound such as
 a car passing, or a precise part in an audio track (e.g.
 chorus or verse)
\end_layout

\begin_layout Description
DataSet A collection of sounds (or tracks).
\end_layout

\begin_layout Description
Sketch A simplified version of an audio scene.
 By simplify we mean any way to approximate the original object via dimensionali
ty reduction.
 We assume the reader is aware of the Sketch 1 paper 
\begin_inset CommandInset citation
LatexCommand cite
key "Suied2013"

\end_inset

.
\end_layout

\begin_layout Description
Fingerprint A hash version of a sketch, that can be stored and retrieved
 efficiently from a fingerprint database
\end_layout

\begin_layout Description
Fingerprint
\begin_inset space ~
\end_inset

Database A hashtable of key/value pairs built from the acoustic fingerprints
 of an entire DataSet.
 The storing and retrieval is facilitated either by an efficient hash indexing
 or a tree structure.
 
\end_layout

\begin_layout Subsection*
Participants
\end_layout

\begin_layout Standard
The project officially started in march 2013.
 WP 1.1 and 1.2 are conducted by Pr.
 L.
 Daudet and Dr.
 M.
 Moussallam.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Building Sound Sketches
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $x\in\mathbb{R}^{N}$
\end_inset

 be a digital signal of finite length 
\begin_inset Formula $N$
\end_inset

.
 A sketch 
\begin_inset Formula $sketch(x)$
\end_inset

 of 
\begin_inset Formula $x$
\end_inset

 is a simplified version of 
\begin_inset Formula $x$
\end_inset

 that can be inverted.
 By simplification, we usually mean that 
\begin_inset Formula $sketch(x)$
\end_inset

 lives in a manifold of a lower dimension than 
\begin_inset Formula $N$
\end_inset

 or that it has a sparse expression in a higher dimensional space.
 Before computing a sketch, one usually uses a representation 
\begin_inset Formula $Rep(x)$
\end_inset

 to transpose the signal in such 
\emph on
feature space
\emph default
.
 A popular choice of representations are the ones that define a mapping
 onto a Time-Frequency plane.
 
\end_layout

\begin_layout Standard
A sketch is thus typically the result of a processing of a representation
 of 
\begin_inset Formula $x$
\end_inset

 (for instance, the selection of the most prominent elements in the feature
 space).
 In a final stage, sketches will be used to build fingerprints 
\begin_inset Formula $fgpt(x)$
\end_inset

.
 Those are designed so as to capture the specificity of a sketch and most
 importantly allow fast and robust comparisons between the sketches of two
 sounds.
\end_layout

\begin_layout Standard
The usual process will thus look like:
\begin_inset Formula 
\[
x\rightarrow Rep(x)\rightarrow sketch(x)\rightarrow fgpt(x)
\]

\end_inset

 Quite naturally, let us now introduce the typical representations, then
 the sketches and finally the fingerprints.
\end_layout

\begin_layout Subsection
Representations
\end_layout

\begin_layout Subsubsection
Spectrograms
\end_layout

\begin_layout Standard
The standard Short-Term Fourier Transform (STFT) is a lapped transform using
 a standard Fourier transform on overlapping (often windowed) segments.
 Let 
\begin_inset Formula $w$
\end_inset

 be a window of size 
\begin_inset Formula $L$
\end_inset

, the STFT of 
\begin_inset Formula $x$
\end_inset

 is indexed in time by the frame (i.e.
 segment) index 
\begin_inset Formula $p$
\end_inset

 (
\begin_inset Formula $0\leq p\leq P-1)$
\end_inset

 and in frequency by 
\begin_inset Formula $k$
\end_inset

 (
\begin_inset Formula $0\leq k\leq k-1)$
\end_inset

:
\begin_inset Formula 
\[
R_{STFT}(x)[p,k]=\frac{1}{\gamma}\sum_{n=0}^{L-1}w[n]\cdot x[n-n_{p}]\cdot\exp\left(-2j\pi k\frac{n}{L}\right)
\]

\end_inset

where 
\begin_inset Formula $\gamma$
\end_inset

 is a normalization factor and 
\begin_inset Formula $n_{p}$
\end_inset

 is the step between two consecutively analyzed frames.
 The STFT is a complex representation, in order to visualize and /or manipulate,
 one usually consider the logarithm of its magnitude.
 This is referred to as the spectrogram of 
\begin_inset Formula $x$
\end_inset

:
\begin_inset Formula 
\[
R_{Spectrogram}(x)=\log\left(|R_{STFT}(x)|\right)
\]

\end_inset

properties:
\end_layout

\begin_layout Enumerate
The STFT has a fixed and linear both in time and frequency resolution.
\end_layout

\begin_layout Enumerate
The STFT is perfectly invertible, provided the Constant Overlap-Add condition
 is fulfilled, meaning basically that the windows are smooth enough and
 must sum to one.
 In practice this is obtained by choosing a Hann window for 
\begin_inset Formula $w$
\end_inset

 and ensuring an overlap of 50% or more (i.e.
 
\begin_inset Formula $n_{p}\leq\frac{L}{2}$
\end_inset

).
\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/exemple_stft.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Spectrogram (Logarithm of the magnitude of the Short Time Fourier Transform)
 of an audio excerpt.
 Darker regions are more energetic.
 The Time/Frequency resolution obeys a compromise that is controlled by
 the analysis window size.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection
Constant Q transform
\end_layout

\begin_layout Standard
The Constant Q transform (CQT) is a TF representation in which the frequency
 scale is logarithmic.
 Unlike the STFT, the CQT cannot be achieved by using a single windowing.
 Instead a filter bank must be defined, whose filters length 
\begin_inset Formula $L_{k}$
\end_inset

 are dyadic in order to ensure that the Q factor:
\begin_inset Formula 
\[
Q=\frac{f_{r}}{\Delta f}
\]

\end_inset

with 
\begin_inset Formula $f_{r}$
\end_inset

 being the resonant frequency of the filter and 
\begin_inset Formula $\Delta f$
\end_inset

 the half-bandwidth, remains constant.
 The representation is then defined by:
\begin_inset Formula 
\[
R_{CQT}(x)[k]=\frac{1}{L_{k}}\sum_{n=0}^{L_{k}-1}w_{k}[n]\cdot x[n]\exp\left(-2j\pi n\frac{f_{k}}{f_{s}}\right)
\]

\end_inset

where 
\begin_inset Formula $w_{k}$
\end_inset

 is a frequency-dependent kernel window, 
\begin_inset Formula $f_{k}$
\end_inset

 are the center frequencies of the filters and 
\begin_inset Formula $f_{s}$
\end_inset

 is the sampling rate.
\end_layout

\begin_layout Standard
In many musical applications (and fingerprinting is no exception 
\begin_inset CommandInset citation
LatexCommand cite
key "gretsi"

\end_inset

), the frequency scale chosen matches the MIDI musical scale.
 A 440Hz A4 is defined by index 69 of the MIDI scale:
\begin_inset Formula 
\[
midi(f)=69+12\log_{2}\left(\frac{f}{440}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Cochleogram
\end_layout

\begin_layout Standard
Also known as auditory spectrum 
\begin_inset CommandInset citation
LatexCommand cite
key "Yang1992,Wang1995"

\end_inset

, the cochleogram is the magnitude of a log-frequency transform similar
 in spirit to the CQT but using real auditory response filters (from the
 cochlea) as the filter banks.
 Cochleograms somewhat emphasize the TF regions that are perceptually stimulated.
 More information should be seeked directly in the papers 
\begin_inset CommandInset citation
LatexCommand cite
key "Yang1992,Wang1995"

\end_inset

 (and other by D.
 Pressnitzer and S.
 Shamma) on which these are based.
 The cochleogram computation is a direct transcription of the one performed
 in the NSL Toolbox
\begin_inset Foot
status open

\begin_layout Plain Layout
Doc and download at http://www.isr.umd.edu/Labs/NSL/Downloads.html
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/exemple_cochleogram.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Cochleogram (absolute value) of an audio excerpt.
 Darker regions are more energetic.
 The frequency scale is logarithmic and the Time/Frequency resolution compromise
 is frequency dependent.
 The filter bank models the first step of the human auditory system.
 Low and high frequencies are typically lowered while frequencies in the
 500-2000Hz range are emphasized.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Corticogram
\end_layout

\begin_layout Standard
Even deeper into the human auditory system is the primary area of the cortex.
 The output of the cochlear system is processed by neuron layers whose action
 can be approximately modeled by 2D wavelet transforms.
 The corticogram is a 4D representation indexed as a scale/rate/time/frequency
 matrix.
 As such it can be figured as a matrix of TF transforms.
 As for above: one should read the paper 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang1995"

\end_inset

 for more details and look into the NSL toolbox.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/exemple_corticogram.pdf
	width 12cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Corticogram visualization as a matrix of time-frequency representations.
 Each of the plots can be understood as a cochleogram that has been filtered
 in 2D.
 Filter characteristics are controlled by the scale and rate parameters.
 In the Top-Left corner, one can see a TF plot that is very smooth both
 in time and frequency.
 Increasing the scale parameters lead to lower plots.
 The Bottom-Left corner plot depicts energy with a good frequency resolution
 but is highly smooth in time.
 At the opposite, the Top-Right corner plots is smooth in frequency but
 sharp in time.
 The Bottom-Right corner somehow presents the high frequencies of the 
\begin_inset Quotes eld
\end_inset

wavelet transform
\begin_inset Quotes erd
\end_inset

 and looks much more like the Cochleogram
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Sparse Multi-Resolution Approximation
\end_layout

\begin_layout Standard
Multi-resolution representations use a union of overcomplete basis (e.g.
 MDCT) to approximate a target audio signal.
 The sparse nature is achieved through selection mechanism such as thresholding
 or greedy algorithms.
 It is a synthesis-based view of the sparse problem.
 There is a huge litterature on these methods, but for practical purposes,
 one can look into the PyMP tutorials
\begin_inset Foot
status open

\begin_layout Plain Layout
http://manuel.moussallam.net/PyMP/
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/sketchified_panzani_XMDCTSparseSketch.pdf
	width 8cm

\end_inset


\begin_inset Graphics
	filename figures/Example_3atoms_mdct.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Left: Spectrogram of the resynthesis of a sparse approximation in a union
 of 3 MDCT basis.
 Red regions are more energetic.
 Right: the 3 types of basic components (or atoms) that are used.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
As one can notice, here the representation is in itself a sketchification
 process.
\end_layout

\begin_layout Subsubsection
SineWave Speech
\end_layout

\begin_layout Standard
The sine wave speech synthesis is obtained by tracking formants (resonant
 frequencies of the vocal track) along time.
 The simplified sound surprisingly reminds of the original.
 This representation is obtained by first finding the formants in the spectrogra
m, then using a Viterbi algorithm for the tracking.
\end_layout

\begin_layout Standard
There is a very good introductory article on sinewave speech on 
\begin_inset CommandInset href
LatexCommand href
name "scholarpedia"
target "http://www.scholarpedia.org/article/Sine-wave_speech"

\end_inset

.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/sketchified_panzani_SWSSketch.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Spectrogram of a SineWave Speech reconstruction of an audio excerpt.
 red regions are more energetic.
 The signal is sliced in evenly spaced time frames.
 In each frame, the formants (resonant frequencies of the vocal track) are
 searched for.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Feature vector
\end_layout

\begin_layout Standard
Any feature extraction process can be used, (MFCC, chroma, LPC, etc..) any
 feature combination can be thought of as a representation of the signal.
 The synthesis can then be obtained by concatenating sounds from a database
 based on nearest neighbors search in the feature space.
 This is for example used in 
\begin_inset CommandInset citation
LatexCommand cite
key "Muller2005"

\end_inset

.
\end_layout

\begin_layout Subsection
Sketches
\end_layout

\begin_layout Standard
A sketch is a simplified version of an audio signal.
 Usually a sketch is obtained by reducing the dimensionality in a transform
 domain.
 Therefore, any combination of a Sparse Approximation algorithm and a specific
 representation (e.g.
 dictionary) constitute a sketch.
 Among such algorithms one can cite:
\end_layout

\begin_layout Itemize
Greedy algorithms such as Matching Pursuit .
 These algorithm alternate the selection of a component of the representation
 and a reprojection of the residual.
\end_layout

\begin_layout Itemize
Thresholding algorithm, (Iterative Hard Thresholding, Soft etc..)
\end_layout

\begin_layout Subsection
Fingerprints
\end_layout

\begin_layout Standard
There is quite a large literature on fingerprinting problems and systems.
 The PhD thesis of J.
 Pinquier 
\begin_inset CommandInset citation
LatexCommand cite
key "Pinquier_phD"

\end_inset

 is a good place to start but a bit old.
 An updated information can be found in S.
 Fenet PhD Thesis that is to be defended quite soon.
 Among very classical fingerprint systems is the one proposed by Haitsma
 
\begin_inset CommandInset citation
LatexCommand cite
key "Haitsma"

\end_inset

, the very famous Shazam system 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang_com"

\end_inset

 and the Phillips one 
\begin_inset CommandInset citation
LatexCommand cite
key "Philips_DCT,Philips_noise"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Families of fingerprints
\end_layout

\begin_layout Standard
There are two families of fingerprinting systems:
\end_layout

\begin_layout Enumerate
The ones that build a single identifier out of an audio signal (e.g.
 a feature vector) and compare audio signals through their computed identifiers.
 (see the review of all such - prior to 2002 - techniques in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cano_review"

\end_inset

)
\end_layout

\begin_layout Enumerate
The ones that use several 
\emph on
Keys 
\emph default
for each
\emph on
 
\emph default
audio signal
\emph on
.
 
\emph default
Comparison between two signals is performed by measuring the amount of Keys
 that they have in common.
\end_layout

\begin_layout Standard
The second approach has proven to be more robust.
 Actually, distortions such as noise, pitch-shifting, compression etc can
 affect the construction of the fingerprints.
 In the first case, if the distortion affects the construction of the identifier
, then recognition would fail.
 
\end_layout

\begin_layout Standard
In the second case, although distortions will certainly modify some 
\emph on
Keys
\emph default
, the usual hypothesis is that 
\emph on
some of them
\emph default
 would remain the same, and sufficiently so as to still be able to identify
 the audio segment.
 This second approach is the one that now prevails in industrials solutions
 such as Shazam and so we shall adopt it here.
\end_layout

\begin_layout Subsubsection
Building Keys
\end_layout

\begin_layout Standard
There are different ways to build 
\emph on
keys, 
\emph default
some of them are listed below:
\end_layout

\begin_layout Enumerate
Peaks and Thresholded values indexes
\end_layout

\begin_deeper
\begin_layout Standard
Whatever the chosen representation (STFT 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

, CQT
\begin_inset CommandInset citation
LatexCommand cite
key "gretsi"

\end_inset

 or Cochleogram) local maxima can be selected and directly used as fingerprint
 keys.
 Nonetheless it's absolute time localization can not serve as a reference
 if shift-invariance is required (which is the case for most fingerprinting
 schemes).
 This is an approach investigated in 
\begin_inset CommandInset citation
LatexCommand cite
key "Moussallam2012c"

\end_inset

.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/fingerprint_panzani_XMDCTSparseSketch.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Visualization of sketch as a sparse collection of Time-Frequency Peaks.
 Each of these dots defines a key.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Pairs of Time-Frequency Peaks
\end_layout

\begin_deeper
\begin_layout Standard
Much more robust than isolated Peaks, Pairs of Peaks have been introduced
 by Wang in the Shazam standard 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang,Wang_com,ismir,gretsi"

\end_inset

.
 The key is now defined by the relative information: 
\begin_inset Formula $(f1,\Delta f,\Delta t)$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/fingerprint_panzani_STFTPeaksSketch.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Visualization of Pairs of Peaks in a TF plane.
 Each of the line specifies a key.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Feature vectors
\end_layout

\begin_deeper
\begin_layout Standard
Along with their binarization (see 
\begin_inset CommandInset citation
LatexCommand cite
key "Haitsma,Muller2005"

\end_inset

)
\end_layout

\end_deeper
\begin_layout Enumerate
Formant differences
\end_layout

\begin_deeper
\begin_layout Standard
A fingerprint specifically dedicated to the SineWave Speech (NEW ONE)
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/fingerprint_panzani_SWSSketch.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Novel type of key.
 At each time step, the differences between formants F2-F1 and F1-F0 are
 computed.
 This gives a pair of frequency differences that are used as a key.
 In the graph, a key is a combination of the blue and green cross at a given
 time position.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
To be explained when will give satisfactory results....
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Subsection
Criteria
\end_layout

\begin_layout Standard
Fingerprinting systems are evaluated on the following criteria:
\end_layout

\begin_layout Itemize
Robustness: To Noise and distortion.
 The inability of a system to detect an excerpt as being part of the database
 is a False Negative
\end_layout

\begin_layout Itemize
Reliability: How often is an excerpt incorrectly identified: this is referred
 to as False Positive 
\end_layout

\begin_layout Itemize
Size: The number of bits required to encode a fingerprint
\end_layout

\begin_layout Itemize
Speed: Or the complexity, measured by Flops or CPU time
\end_layout

\begin_layout Itemize
Scalability: Will the system continue to perform if the database is about
 million songs
\end_layout

\begin_layout Subsection
Noise Robustness
\end_layout

\begin_layout Standard
Here we measure the amount of keys that are not affected by additive white
 noise:
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/NoiseRobustness_k50.pdf
	width 8cm

\end_inset


\begin_inset Graphics
	filename figures/NoiseRobustness_k200.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Key Robustness to additive white noise.
 Left k=200, Right k=50
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Results on recognition tasks
\end_layout

\begin_layout Itemize
Setup: GTZAN dataset (1000 songs of 30 seconds each 
\begin_inset Formula $\sim$
\end_inset

8.3 hours).
 Segments of 5 seconds.
\end_layout

\begin_layout Standard
We run a recognition experiment with various levels of sparsities in the
 sketch, leading to various number of keys.
 These keys are stored in specific Hash Tables for highly efficient search
 and retrieval.
 The size of the hash table is here used to illustrate the performances.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/GTZAN_Scores_2fgpts_dur5.pdf
	width 12cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Recognition score on the GTZAN dataset with STFT and Cochleograms pairs
 of peaks.
 Cochleograms seems to allow for slightly better recognition score for a
 given sketch sparsity level.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Setup: RWC sub dataset (80 songs of a few minutes each 
\begin_inset Formula $\sim$
\end_inset

 5.5 hours).
 Segments of 5 seconds.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/RWCLearn_Scores_2fgpts_dur5.pdf
	width 12cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Recognition score on a subset of the RWC pop dataset with STFT and Cochleograms
 pairs of peaks.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Experiments still to make
\end_layout

\begin_layout Itemize
We have yet many sketches (with many parameters) to try for fingerprinting
\end_layout

\begin_layout Itemize
Results on Speech dataset of tens of thousands of short speech: we may also
 want to know distance to same phrase by different locutor..
\end_layout

\begin_layout Itemize
Other types of distortions should be investigated:
\end_layout

\begin_deeper
\begin_layout Itemize
time shift
\end_layout

\begin_layout Itemize
frequency shift
\end_layout

\begin_layout Itemize
compression
\end_layout

\begin_layout Itemize
echo
\end_layout

\end_deeper
\begin_layout Itemize
Find an equivalent of priming in the fingerprinting problem
\end_layout

\begin_layout Itemize
Find a robust fgpt with sinewave speech 
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Implementation details
\end_layout

\begin_layout Subsection
Language and libraries
\end_layout

\begin_layout Standard
A unified framework has been developed in Python (2.0 syntax).
 It has been tested on linux and windows and should straightforwardly work
 on mac also.
 The manipulation of audio signals, spectrogram construction, and sparse
 greedy algorithms are performed through the use of the PyMP
\begin_inset Foot
status open

\begin_layout Plain Layout
Download at https://github.com/mmoussallam/PyMP
\end_layout

\end_inset

 library, for which I have written some tutorials
\begin_inset Foot
status open

\begin_layout Plain Layout
At: http://manuel.moussallam.net/PyMP/
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
PyMP installation is relatively easy once the following Python packages
 have been installed:
\end_layout

\begin_layout Itemize
Numpy/Scipy 
\end_layout

\begin_layout Itemize
Matplotlib
\end_layout

\begin_layout Itemize
scikits.audiolab
\end_layout

\begin_layout Itemize
scikits.learn
\end_layout

\begin_layout Standard
On any platform, all of these can be easily installed using easy_install
 software of pip.
\end_layout

\begin_layout Standard
In order to work properly, additional (but quite standard and definitely
 cross platform) libraries will be required:
\end_layout

\begin_layout Itemize
fftw3 
\begin_inset Foot
status open

\begin_layout Plain Layout
Doc and Download at http://www.fftw.org/
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
libsndfile 
\begin_inset Foot
status open

\begin_layout Plain Layout
Doc and download at http://www.mega-nerd.com/libsndfile/
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Versionning
\end_layout

\begin_layout Standard
All the source code developed in this project so far is versioned using
 
\emph on
git 
\emph default
and is stored in a (private and secured) repository on github.
 The code is object-oriented as much as possible, which means the sounds,
 sketches, representation, fingerprints and databases are Python objects.
 Experiments are plain python scripts.
\end_layout

\begin_layout Paragraph
Tests
\end_layout

\begin_layout Standard
Some tests have been written.
 Mainly to guarantee back compatibility.
 They are located in the tests package.
\end_layout

\begin_layout Paragraph
Speech analysis
\end_layout

\begin_layout Standard
For computing the sws, we use the praat
\begin_inset Foot
status open

\begin_layout Plain Layout
Doc and download at http://www.fon.hum.uva.nl/praat/
\end_layout

\end_inset

 software since it has a built-in formant tracking algorithm.
 It is not very handy to use but it might be the fastest way for now.
 If Sws appears to be more interesting in the future we may have to re-implement
 this part.
 Praat is stable on linux based system but I haven't tried it on windows
 platforms so far.
\end_layout

\begin_layout Subsection
Sketches
\end_layout

\begin_layout Standard
All sketches inherit from an abstract interface AudioSketch as the following
 figure shows:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../classes/classes_Sketches.png
	lyxscale 20
	width 16cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
UML diagram of the sketches objects.
 There is a unique abstract interface for audio sketches.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
A nice way to discover the different sketches is by launching the test script
 SketchTest.py
\end_layout

\begin_layout Subsection
Fingerprints
\end_layout

\begin_layout Standard
All fingerprinting systems uses the same interface as depicted below:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../classes/classes_FgptHand.png
	lyxscale 20
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
UML diagram of the fingerprint handler objects.
 There is a unique abstract interface that deals with the low level hash
 table system.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
More explanations to come
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/home/manu/Documents/Global-Fingerprint,/home/manu/Documents/Global-Fingerprint-sketch,/home/manu/Documents/Global-Perception,/home/manu/Documents/Global-Own"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
