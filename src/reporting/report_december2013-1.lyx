#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass report
\use_default_options true
\begin_modules
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 3cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle headings
\bullet 0 1 1 -1
\bullet 1 0 31 -1
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Je n'ai pas la figure du logo...
 :)
\end_layout

\end_inset


\end_layout

\begin_layout Title
Technical report on project Sketch II
\end_layout

\begin_layout Date
dec.
 2013
\end_layout

\begin_layout Author
M.
 Moussallam, L.
 Cornu L.
 Daudet
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Context of this study
\end_layout

\begin_layout Chapter
Representation of sound
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Manu
\end_layout

\end_inset


\end_layout

\begin_layout Section
Time-Frequency Representations
\end_layout

\begin_layout Subsection
Linear Fourier : STFT
\end_layout

\begin_layout Subsection
Logarithmic: CQT
\end_layout

\begin_layout Standard
The constant-Q transform is a signal Time/Frequency representation in which
 the frequency scale is logarithmic.
 The CQT can be considered as a bank of filters, where the resonant frequencies
 are logarithmic scale spaced, and the quality factor Q remains constant:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{Q=\frac{f_{k}}{\Delta f}}
\]

\end_inset

with 
\begin_inset Formula $\mathrm{f_{k}}$
\end_inset

 being the eigen frequency of the filter and 
\begin_inset Formula $ $
\end_inset


\begin_inset Formula $\mathrm{\Delta f_{k}}$
\end_inset

 the bandwidth of the resonant frequency.
 Whose filters lengths 
\begin_inset Formula $L_{k}$
\end_inset

 are dyadic and inversely proportional to the resonant frequency in order
 to keep a constant factor Q.
 The representation is then defined by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
R_{CQT}(x)[k]=\frac{1}{L_{k}}\sum_{n=0}^{^{L_{k}-1}}w_{k}[n].x[n]exp\left(-2j\pi n\frac{f_{k}}{f_{s}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $w_{k}$
\end_inset

 is a Hann window with a size 
\begin_inset Formula $L_{k}$
\end_inset

 frequency-dependent, 
\begin_inset Formula $f_{k}$
\end_inset

 are the center frequencies of the filters and 
\begin_inset Formula $f_{s}$
\end_inset

 is the sampling rate.
\end_layout

\begin_layout Standard
The frequency scale can be chosen in order to fit with the MIDI musical
 scale (index semitone: interval between two adjacent notes in a 12-tone
 scale), that property made this representation often use in musical signal
 analysis.
 The note A4, witch correspond to the frequency 440Hz is defined by the
 index 69 in the MIDI scale, by using the relation above, we fit the frequency
 scale to the MIDI musical one:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
midi(f)=69+12log_{2}\left(\frac{f}{440}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/cqtIHT.png
	scale 50
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Constant Q Transform (magnitude of the output of constant-Q filters) of
 the phrase 'we will have to watch our chances'.
 darker regions are more energetic.
 The Time/Frequency resolution depends on the frequency.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The advantage of CQT is that it is an invertible representation.
 The probleme is that to keep the property of invertibility, the temporal
 step between two analysed frames have to be smaller than the frame of the
 higher frequency (wich can be very small, about 1millisecond for a frequency
 of 16kHz).
 This leed to high cost in calculation.
\end_layout

\begin_layout Subsection
Cochleograms
\end_layout

\begin_layout Standard
The auditory system is thought to contain an array of over-lapping band-pass
 filters known as ‘auditory filters’.
 They occur along the basilar membrane and increase the frequency selectivity
 of the cochlea and therefore the listener’s discrimination between different
 sounds.
 The basiliar membrane is a part of the cochlea, and cochleograms model
 the transformation made by these 'auditory models'.
 This transformation is mainly similar that the one use for the CQT, but
 using a real auditory response filter as the filter banks.
 The main difference between the CQT filter and those are there non-symmetricaln
ess of each filters.
 A auditory filter centered in the frequency 
\begin_inset Formula $f_{c}$
\end_inset

 is writing in the time domain as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
gt(t)=at^{(n-1)}exp\left(-2\pi bt\right)cos\left(2\pi f_{c}t+\phi\right)
\]

\end_inset


\end_layout

\begin_layout Standard
it is basically a cosine widowed by a non-symetric widows that is the product
 of a power term and a decresing exponential.
 The parameters of each filters mainly control the duration end therefore
 the bandwidth.
 In this study we used the same set of coefficients filter as in existing
 software (i.e the NSL toolbox).
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/cochleoPP.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
cochleogram (absolute value) of the phrase 'we will have to watch our chances'.
 darker regions are more energetic.
 The frequency scale is logaithmic and the Time/Frequency resolution is
 frequency dependent.
 low and high frequencies are lowered.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The cochleogram is the represention in Time/Frequency of the output of the
 magnitude of auditory filters.
 We can see in the next figure that they emzophasize the magnitude over
 the frequency spectrum according to the human sensivity of tones.
 A nice introduction can be found in []...
\end_layout

\begin_layout Section
Scale-Space Representations
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
laure
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Wavelet-based transform
\end_layout

\begin_layout Standard
As we seen in the previous part, the resolution of time and frequency in
 a STFT representation obey to a firm compromise established before the
 analysis of the audio signal.
 In order to get a good resolution in time we need to use sharp windows
 that will affect the resolution of frequencies.
 The inverse is true, a good resolution in frequencies imply a long analyzed
 window decreasing the time resolution.
 But having a good resolution for the both of them is not possible, this
 property is related to the Heisenberg uncertainty principle.
 Somehow the wavelet were developed to resolve this problem.
 
\end_layout

\begin_layout Standard
The wavelet analysis was introduced by J.
 Morlet.
 It is not based on a representation of frequencies over time, but in transitory
 component present in the signal.
 In this idea, the wavelet transform decompose the signal in different scaled
 and translated version of the mother wavelet.
 The mother wavelet is a function 
\begin_inset Formula $\psi$
\end_inset

 
\begin_inset Formula $\in L\mathbf{^{2}(\mathrm{\mathbb{R}})}$
\end_inset

, zero mean, normalised, centered in 
\begin_inset Formula $t=0$
\end_inset

, the shape is adapted on what we want to analyze.
 In audio signal we often use a windowed sinusoid.
\end_layout

\begin_layout Standard
A set of Frequency/Time atoms, are obtained by a scaling 
\begin_inset Formula $s$
\end_inset

, and a translation 
\begin_inset Formula $u$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\psi_{u,s}(t)=\frac{1}{\sqrt{s}}\psi\left(\frac{t-u}{s}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The weight of each of these scaled and translated version of the mother
 wavelet form the wavelet transform of the signal.
 It is a function of two variables, time and scale and give an alternative
 representation on 
\begin_inset Formula $f_{t}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Wf(u,s)=\langle f,\psi_{u,s}\rangle=\int_{-\infty}^{+\infty}f(t)\frac{1}{\sqrt{s}}\psi^{*}\left(\frac{t-u}{s}\right)dt
\]

\end_inset


\end_layout

\begin_layout Standard
because of the infinite sum this representation is very redundant.
 To avoid this we use discrete time and scale variables.
 Choosing 
\begin_inset Formula $k$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

, the discrete variables 
\begin_inset Formula $s=2^{j}$
\end_inset

 and 
\begin_inset Formula $u=k2^{j}$
\end_inset

, we can find a mother wavelet 
\begin_inset Formula $\psi(t)$
\end_inset

 such that the wavelet set form a orthonormal basis of the function in 
\begin_inset Formula $\mathcal{C^{\mathrm{2}}}$
\end_inset

.
\end_layout

\begin_layout Standard
If the input is a two dimensional data the wavelet basis is obtained over
 the continuous domain by the union of translating and dilating three mother
 wavelet functions 
\begin_inset Formula $\left\{ \psi^{V},\psi^{H},\psi^{D}\right\} $
\end_inset

.
\end_layout

\begin_layout Standard
Each wavelet atom is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\psi_{k,j,n}(t)=\psi_{k,j}^{n}(t)==\frac{1}{\sqrt{2^{j}}}\psi^{n}\left(\frac{t-k2^{j}}{2^{j}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $s=2^{j}$
\end_inset

 , and the translation is 
\begin_inset Formula $u=2^{j}(k_{1},k_{2})$
\end_inset

, the computation do all the inner products .
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/lenaWavelet.eps
	scale 40
	BoundingBox -150bp 60bp 200bp 600bp
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Wavelet transform of an image, each plot can be understand as output of
 an inner product with a specific scaled, translated wavelet.
 They are tree different mother wavelets, 
\begin_inset Formula $\left\{ \psi^{V},\psi^{H},\psi^{D}\right\} $
\end_inset

 to form an orthogonal basis, respectively vertical, horizontal and diagonal.
 From the bottom right to the top left, the output of inner products with
 signal and scaled wavelet are ranked from the broadest scale to the sharpest.
 We observed that the representation with broad scaled wavelet show blured
 contour of discontinuty.
 This representation is obtained by using the Toolbox image.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A mother wavelet with 
\begin_inset Formula $n$
\end_inset

 nuls moments is the n-derivative of a function 
\begin_inset Formula $\theta$
\end_inset

.
 This means that the wavelet transformm is a multiscale differential operator.
 The local regularity is then carcaterised by decreasing wavelets coefficients
 and local irregularity is emphasize by local maxima coefficients small
 scale.
\end_layout

\begin_layout Subsection
Corticograms
\end_layout

\begin_layout Standard
The primary auditory cortex is the part of the brain responsible of the
 understanding and segregation of equally tuned sound with temporal structure
 dissimilarity.
 After the cochlea processing the sound perceived are oredred along the
 tonotopic axis, witch means that they are projected according the cochlea
 shape, then ranking according their wavelength in particular area of brain.
 
\end_layout

\begin_layout Standard
Then the primary cortex analysed the spectro-temporal content of the sound
 using layers of neuron.
 Those neurons, act as bank of filters, centered in each frequencies of
 the tonotopic axis.
 Each filter is tuned at a specific rate (temporal modulation in Hertz)
 and scale (frequency modulation in cycle/octave).
 Those actions can be approximately seen as a bank of 2D wavelet transform.
 
\end_layout

\begin_layout Standard
The characteristic function of each neuron are the STRF (spectro-temporal
 response field), showing the exhibiting and inhibitory fields in frequencies
 and time.
 The spectro-temporal variations af theses field are formed by 
\shape italic
ripples 
\shape default
(sound with a spectral pattern that have a sinusoidal shape along the logarithmi
c frequency axis).
 The mathematical model of the STRF is shown below:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
STRF=h_{IRT}(t)\star h_{IRS}(x)
\]

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $ $
\end_inset


\begin_inset Formula $h_{IRT}(t)$
\end_inset

 and 
\begin_inset Formula $h_{IRS}(x)$
\end_inset

 are two ripples parametrised by the caracteristics of a specific neuron.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{IRT}(t,w,\theta)=h_{t}(t;w)cos\theta+\hat{h_{t}}(t;w)sin\theta
\]

\end_inset

where 
\begin_inset Formula $w$
\end_inset

 and
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\Omega$
\end_inset

 are the rates and scales, and 
\begin_inset Formula $\phi$
\end_inset

, 
\begin_inset Formula $\theta$
\end_inset

 are the carcteristics phases of asymetry.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
r\pm(t,f;w,\Omega;\theta,\phi)=z(t,f)\star_{t,f}STRF\pm(t,f;w,\Omega;\theta,\phi)
\]

\end_inset


\end_layout

\begin_layout Standard
r is the response of each cochleograms convolued in time and frequency by
 a bank of STRF.
 We can see the Corticogram as a repeated cochleogram viewed at different
 resolution, or as a bank of different spectral and temporal modulation
 filters with different tunning (from narrowband to broadband).
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/cortico1.png
	BoundingBox 0bp 20bp 432bp 288bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Corticograms visualization as a matrix of time-frequency representations.
 Each of the plots can be understood as a cochleogram filtered in 2D (rates
 and sclaes).
 Filter frequency are controlled by the scale and the rate parameters.
 In the top left pannel we see a represation with broadband filters in rates
 and scales.
 In bottom right we see a represention with sharpband filter of rate and
 scale, somehow representing the high frequencies of the 'wavelet transform'
 and is closed to the cochleogram.
 The botom right and top left are representation with sharp modulation in
 frequencies and time respectivelly.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The corticogram is a 4D representation indexed by scale/rate/time/frequency
 matrix.
 As such it can be figured as a set of matrix of Time/Frenquency representation.
 interested reader can look a the paper ...
 into detail for better understanding of the computational detail of corticogram
s.
 The implementation here is provided by the NSL toolbox.
\end_layout

\begin_layout Subsection
Quorticograms
\end_layout

\begin_layout Standard
As the CQT offer beter performances in computation time and is invertible,
 we simplified the Corticogram by remplacing the imput cochleogram by a
 CQT.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/cortico2.png
	BoundingBox 0bp 20bp 432bp 288bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Quorticograms visualization as a matrix of time-frequency representations.
 Each of the plots can be understood as a constant Q transform filtered
 in 2D (rates and sclaes).
 Filter frequency are controlled by the scale and the rate parameters.
 In the top left pannel we see a represation with broadband filters in rates
 and scales.
 In bottom right we see a represention with sharpband filter of rate and
 scale, somehow representing the high frequencies of the 'wavelet transform'
 and is closed to the CQT.
 The botom right and top left are representation with sharp modulation in
 frequencies and time respectivelly.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Other Representations
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
manu
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
SineWave Speech
\end_layout

\begin_layout Subsection
Feature transforms
\end_layout

\begin_layout Chapter
Measuring similarities between sounds sketches using a Fingerprinting approach
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Manu
\end_layout

\end_inset


\end_layout

\begin_layout Section
Ideas and concepts
\end_layout

\begin_layout Subsection
The evaluation problem
\end_layout

\begin_layout Subsection
Using Fingerprint as a proxy measure
\end_layout

\begin_layout Section
A fingerprinting framework
\end_layout

\begin_layout Subsection
Standard audio fingerprinting approaches
\end_layout

\begin_layout Standard
Audio objects recognition systems aim at the automatic retrieval of a signal
 
\begin_inset Formula $y$
\end_inset

 among a collection of known sounds objects 
\begin_inset Formula $\{y^{(i)}\}$
\end_inset

.
 In practice, such collection can be very large and sounds are complicated
 objects to compare.
 For this retrieval to be effective, the search must be performed efficiently,
 for instance by comparing low-dimensional 
\emph on
proxies
\emph default
 of the objects, or fingerprints.
\end_layout

\begin_layout Standard
An audio fingerprint is a collection of signal-characteristic features that
 present some robustness to distortions and can be efficiently compared
 to others.
 There are two big families of audio fingerprinting systems, the first one
 adopts a bag of features approach.
 A low-dimensional vector of features (eg.
 Chroma, MFCC, etc..) is thus used as the fingerprint.
 It has essentially been proposed by Haitsma 
\begin_inset CommandInset citation
LatexCommand cite
key "Haitsma"

\end_inset

 with binarized Chroma.
 A review of such methods can be found in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cano_review"

\end_inset

 with more recent avatars being based on wavelet transforms 
\begin_inset CommandInset citation
LatexCommand cite
key "Baluja2007"

\end_inset

 or finer frequency models 
\begin_inset CommandInset citation
LatexCommand cite
key "Betser_article,Dupraz_article"

\end_inset

.
\end_layout

\begin_layout Standard
The second family of methods is similar in spirit to some feature extraction
 methods developed in image processing.
 It has first emerged with the work of Wang 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

 and is based on the idea of selecting a subset of 
\emph on
keypoints
\emph default
 in a Time-Frequency (TF) representation, pairing them to form 
\emph on
landmarks
\emph default
 and using each of these 
\emph on
landmarks
\emph default
 as an index in a structured database (
\emph on
e.g.

\emph default
 a hash-table or any fast indexing system).
 This approach is at the basis of the well known Shazam service 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang_com"

\end_inset

, but also led to the works of Cotton and Ellis
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

 and Fenet
\emph on
 et al
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

 among others.
 While in his seminal work 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang"

\end_inset

, Wang selected 
\emph on
keypoints
\emph default
 as local maxima in a simple spectrogram, Cotton and Ellis 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

 use a greedy algorithm on a multiscale Gabor dictionary and Fenet 
\emph on
et al
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

 propose a logarithmic transform instead of windowed Fourier.
\end_layout

\begin_layout Standard
All of these methods share a common formalism, that is conveniently exposed
 using a dictionary-based point of view.
 Given a dictionary 
\begin_inset Formula $\Phi$
\end_inset

, one seeks a combination of 
\begin_inset Formula $k$
\end_inset

 elements of 
\begin_inset Formula $\Phi$
\end_inset

 (labeled 
\emph on
atoms
\emph default
) that can be efficiently used as 
\emph on
keypoints
\emph default
 in a fingerprinting system.
 State of the art methods, mainly proposes different dictionaries (
\emph on
e.g.

\emph default
 Gabor 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang,Wang_com"

\end_inset

, Union of Gabor
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010"

\end_inset

, MDCT 
\begin_inset CommandInset citation
LatexCommand cite
key "Moussallam2012c"

\end_inset

, Logarithmic 
\begin_inset CommandInset citation
LatexCommand cite
key "ismir"

\end_inset

..) and selection algorithms (Local Peak Picking 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang,Wang_com,ismir"

\end_inset

, Matching Pursuit 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010,Moussallam2012c"

\end_inset

).
\end_layout

\begin_layout Subsection
Problem
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\boldsymbol{y}\in\mathbb{E}^{N}$
\end_inset

 be a 
\begin_inset Formula $N$
\end_inset

 - dimensional discrete signal (
\begin_inset Formula $\boldsymbol{E}=\mathbb{R}$
\end_inset

 or 
\begin_inset Formula $\mathbb{C}$
\end_inset

) and 
\begin_inset Formula $\boldsymbol{\Phi}=\{\phi_{i}\}_{i=1..M}$
\end_inset

 a dictionary of 
\begin_inset Formula $M$
\end_inset

 
\emph on
atoms 
\emph default

\begin_inset Formula $\boldsymbol{\phi}_{i}$
\end_inset

 of same dimension than 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, one speaks of a 
\emph on
representation
\emph default
 
\begin_inset Formula $\hat{y}$
\end_inset

 of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 in 
\begin_inset Formula $\Phi$
\end_inset

 as a linear combinations of the atoms, 
\emph on
i.e.

\emph default
 
\begin_inset Formula $\hat{y}=\sum_{i=1}^{M}\alpha_{i}\phi_{i}$
\end_inset

 where the weights coefficients stacked in an 
\begin_inset Formula $M-$
\end_inset

dimensional vector 
\begin_inset Formula $\boldsymbol{\alpha}$
\end_inset

 now carry the information.
 The nature and quantity of information conveyed by each (or a combination
 of) 
\begin_inset Formula $\alpha_{i}$
\end_inset

 depends on how the dictionary is designed and what
\emph on
 a priori 
\emph default
knowledge on the signal is available.
 
\end_layout

\begin_layout Standard
In an audio fingerprint context, it is interesting to further decompose
 
\begin_inset Formula $\boldsymbol{\alpha}$
\end_inset

 as the element-wise product 
\begin_inset Formula $\boldsymbol{\alpha}=\boldsymbol{x}\odot\boldsymbol{s}$
\end_inset

 where 
\begin_inset Formula $x$
\end_inset

 is real or complex valued and 
\begin_inset Formula $\boldsymbol{s}$
\end_inset

 is called the support and restricted to binary values: 
\begin_inset Formula $s_{i}=$
\end_inset

1 if the atom is selected as a keypoint and zero otherwise.
\end_layout

\begin_layout Standard
In this formalism, limiting the number of keypoints can be straightforwardly
 transcribed as a sparsity constraint on 
\begin_inset Formula $s$
\end_inset

.
 The robustness property is harder to characterize since different types
 of distortions may occur.
 For the sake of clarity, let us consider only the case of additive white
 Gaussian noise.
 The best way to resist such distortion is to select atoms minimizing a
 reconstruction error.
 More generally, most types of robustness can be enforced by constraints
 of 
\emph on
descriptiveness
\emph default
 of the keypoints.
 
\end_layout

\begin_layout Standard
Expressing the discriminative power, however, is more challenging.
 This can be done by using information theoretic metrics in general and
 entropy in particular.
 Audio signals often carry more energy in their low than high-frequencies.
 Corresponding keypoints thus have a higher probability of being selected.
 Intuitively, they provide a less discriminant information on a signal that
 the least probables ones.
 If one is able to fully evaluate the probability distribution of the support
 then one would want to constrain its 
\emph on
entropy
\emph default
 to be the highest possible.
\end_layout

\begin_layout Standard
The problem of finding 
\begin_inset Formula $k$
\end_inset

 keypoints that have maximum descriptive and discriminative potentials can
 thus be stated as:
\begin_inset Formula 
\begin{equation}
\mathcal{P}_{\lambda,k}=\min_{s}\|y-\sum_{i=1}^{M}x_{i}.s_{i}.\phi_{i}\|_{2}-\lambda H_{\Phi}(s)\mbox{ s.t. }\sum_{i=1}^{M}s_{i}=k\label{eq:problem_full}
\end{equation}

\end_inset

where 
\begin_inset Formula $H_{\Phi}(s)$
\end_inset

 is the entropy of the vector 
\begin_inset Formula $s$
\end_inset

 given the dictionary.
\end_layout

\begin_layout Subsection
Architecture
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/schema.png
	lyxscale 25
	height 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Architecture of a fingerprint-based recognition system
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Generalization
\end_layout

\begin_layout Subsection
A unifying model
\end_layout

\begin_layout Standard
By definition, 
\begin_inset Formula $H_{\Phi}(s)$
\end_inset

 only exists when the probabilistic distribution of 
\begin_inset Formula $s$
\end_inset

 is available.
 Experimentally, one is able to characterize quite efficiently this distribution.
 Let 
\begin_inset Formula $\Phi$
\end_inset

 be a time-frequency dictionary, and let us observe the solutions to 
\begin_inset Formula $\mathcal{P}_{0,k}$
\end_inset

, that is the sparse reconstruction problem without entropic constraint.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Empirical-Biais"

\end_inset

 displays the empirical distribution of the first 100 keypoints selected
 with a algorithm from the Matching Pursuit (MP 
\begin_inset CommandInset citation
LatexCommand cite
key "Mallat_TSP1993"

\end_inset

) family as in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cotton2010,Moussallam2012c"

\end_inset

.
 The dictionary is a union of 7 MDCT scales replicated such as to form a
 highly over-complete shift-invariant dictionary of roughly 65 millions
 atoms.
 Atoms are uniformly selected in time while a strong bias on their frequency
 localization can be observed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/All100Atoms_GTZAN_100files_7xMDCT.png
	lyxscale 20
	width 8cm

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Empirical Time-Frequency positions of the first 100 selected atoms (blue
 dots) and their marginal distributions observed on 600 audio segments of
 5 seconds each, taken from the GTZAN
\begin_inset CommandInset citation
LatexCommand cite
key "Tzanetakis2002"

\end_inset

 dataset.
 Signals are down-sampled to 8KHz.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Empirical-Biais"

\end_inset

 The marginal on frequency is presented in log scale.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/WF_WT_200files_1xMDCT_100k.pdf
	width 8cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Empirical Co-occurrence of Time Frequency atoms observed on the same 600
 segments.
\begin_inset CommandInset label
LatexCommand label
name "fig:Empirical-Covariance"

\end_inset

.
 The empirical bias has been subtracted.
 Darker regions indicate higher co-occurrences.
 The strong diagonal components indicates neighborhood relationships both
 in time and frequency.
 Harmonic correlations can be observed in the frequency matrix.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
At en even deeper level, one can empirically observe the covariance matrix
 of the support.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Empirical-Covariance"

\end_inset

 shows experimental co-occurrences of keypoints relative to their frequency
 and time index respectively.
 Both matrices have strong coefficients near the diagonals, it reveals the
 neighborhood correlations between keypoints close to each other in the
 time-frequency plane.
 The frequency matrix also exhibit strong subdiagonals that reflect the
 harmonic correlations.
\end_layout

\begin_layout Standard
This basically tells us that landmarks built on neighboring and harmonically
 related keypoints are less informative (
\emph on
i.e.

\emph default
 discriminative) than others.
\end_layout

\begin_layout Subsection
A hybrid approach
\end_layout

\begin_layout Standard
Addressing problem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:problem_full"

\end_inset

 is a complicated issue.
 Indeed, even with 
\begin_inset Formula $\lambda=0$
\end_inset

, it requires either a relaxation of the sparsity constraint or the use
 of suboptimal greedy algorithms such as MP.
 Given that the hard sparsity constraint is strict in this case, we have
 chosen to modify an MP algorithm by simply changing the atom selection
 rule.
 
\end_layout

\begin_layout Standard
Such algorithm makes a series of local decisions (
\emph on
i.e.

\emph default
 keypoint selection), based only on the knowledge of the previous choices
 (
\emph on
i.e.

\emph default
 which keypoints have already been selected).
 The residual signal 
\begin_inset Formula $r^{n}$
\end_inset

 at iteration 
\begin_inset Formula $n$
\end_inset

 is usually updated by subtracting from the original signal its projection
 on the subspace spanned by the selected atoms.
 At iteration 
\begin_inset Formula $n$
\end_inset

 the decision boils down to solving:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\arg\max_{\phi_{i}\in\Phi}|\langle r^{n},\phi_{i}\rangle|(1+\lambda_{H}H(\phi_{i}|s_{n-1}))
\end{equation}

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $H(\phi_{i}|s_{n-1})$
\end_inset

 is the
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 entropy of choosing atom 
\begin_inset Formula $\phi_{i}$
\end_inset

 knowing the support 
\begin_inset Formula $s_{n-1}$
\end_inset

 and writes: 
\begin_inset Formula 
\begin{eqnarray}
H(\phi_{i}|s_{n-1}) & = & -p(\phi_{i}|s_{n-1})\log\left[p(\phi_{i}|s_{n-1})\right]\nonumber \\
 & = & \frac{\log\left[1+\sum_{j\in\Gamma_{n-1}}w_{ij}+b_{i}\right]}{1+\sum_{j\in\Gamma_{n-1}}w_{ij}+b_{i}}
\end{eqnarray}

\end_inset

with 
\begin_inset Formula $\Gamma_{n-1}$
\end_inset

 being the indices of the non zero elements of 
\begin_inset Formula $s_{n-1}$
\end_inset

, 
\emph on
i.e.

\emph default
 the keypoints selected so far.
 An advantage of this algorithm is that it can be quickly implemented using
 existing MP libraries such as PyMP
\begin_inset Foot
status open

\begin_layout Plain Layout
https://github.com/mmoussallam/PyMP
\end_layout

\end_inset

.
 Additionally, existing algorithms can be seen as particular cases.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/KeyPoints_and_pairs_voicefemale_30k.pdf
	width 16cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Time-frequency 
\emph on
landmarks
\emph default
 built by the algorithm with varying parameters on a 5s audio excerpt of
 female speech.
 Each case has built 100 landmarks.
 (a): C10 (
\begin_inset Formula $\lambda_{H}=0$
\end_inset

) (b): 
\begin_inset Formula $\lambda_{H}=1\,(0,W)$
\end_inset

 (c): 
\begin_inset Formula $\lambda_{H}=10\,(b,W)$
\end_inset

(d): W03
\begin_inset CommandInset label
LatexCommand label
name "fig:TF-landmarks"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Distances in the fingerprint domain
\end_layout

\begin_layout Chapter
Experiences and results
\end_layout

\begin_layout Section
Sparsity-based sketches
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Mettre les comparaisons entre shazam et la même chose avec cqt/cochléo et
 IHT
\end_layout

\end_inset


\end_layout

\begin_layout Section
Sine-Wave speech
\end_layout

\begin_layout Section
Finding invariants
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Ici mettre plein de figures : les corticogrammes sur les voix même phrase/locute
ur diff , même locuteur/phrase diff etc..
\end_layout

\end_inset


\end_layout

\begin_layout Section
What works and what don't
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Ici un récapitulatif de ce qui marche et de ce qui marche pas
\end_layout

\end_inset


\end_layout

\begin_layout Chapter*
And now...
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Manu/Laure
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Achievements
\end_layout

\begin_layout Itemize
Plateform of testing
\end_layout

\begin_layout Itemize
Modelling of the fingerprint framework
\end_layout

\begin_layout Section*
Self-criticism
\end_layout

\begin_layout Itemize
How good is fingerprint as a proxy measure for similarities?
\end_layout

\begin_layout Section*
Link with next WP
\end_layout

\begin_layout Itemize
Our recommendations for real tests: SWS or Scale/Space blurred approximates
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/home/manu/Documents/Global-Fingerprint,/home/manu/Documents/Global-Fingerprint-sketch,/home/manu/Documents/Global-Perception,/home/manu/Documents/Global-Own,/home/manu/Documents/Global"
options "bibtotoc,abbrv"

\end_inset


\end_layout

\end_body
\end_document
