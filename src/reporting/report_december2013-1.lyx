#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass report
\use_default_options true
\begin_modules
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 3cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle headings
\bullet 0 1 1 -1
\bullet 1 0 31 -1
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Technical report on project Sketch II
\end_layout

\begin_layout Date
dec.
 2013
\end_layout

\begin_layout Author
M.
 Moussallam, L.
 Cornu L.
 Daudet
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Context of this study
\end_layout

\begin_layout Chapter
Representation of sound
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Manu
\end_layout

\end_inset


\end_layout

\begin_layout Section
Time-Frequency Representations
\end_layout

\begin_layout Subsection
Linear Fourier : STFT
\end_layout

\begin_layout Subsection
Logarithmic: CQT
\end_layout

\begin_layout Standard
The constant-Q transform is a signal Time/Frequency representation in which
 the frequency scale is logarithmic.
 The CQT can be considered as a bank of filters, where the resonant frequencies
 are logarithmic scale spaced, and the quality factor Q remains constant:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{Q=\frac{f_{k}}{\Delta f}}
\]

\end_inset

with 
\begin_inset Formula $\mathrm{f_{k}}$
\end_inset

 being the natural frequency of the filter and 
\begin_inset Formula $ $
\end_inset


\begin_inset Formula $\mathrm{\Delta f_{k}}$
\end_inset

 the bandwidth of the resonant frequency.
 Whose filters lengths 
\begin_inset Formula $L_{k}$
\end_inset

 are dyadic and inversement proportional to the resonant frequency in order
 to keep a constant factor Q.
 The representation is then defined by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
R_{CQT}(x)[k]=\frac{1}{L_{k}}\sum_{n=0}^{^{L_{k}-1}}w_{k}[n].x[n]exp\left(-2j\pi n\frac{f_{k}}{f_{s}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $w_{k}$
\end_inset

 is a hann window with a size 
\begin_inset Formula $L_{k}$
\end_inset

 frequency-dependant, 
\begin_inset Formula $f_{k}$
\end_inset

 are the center frequencies of the filters and 
\begin_inset Formula $f_{s}$
\end_inset

 is the sampling rate.
\end_layout

\begin_layout Standard
The frequency scale can be chosen in order to fit with the MIDI musical
 scale (index semitone: interval between two adjacent notes in a 12-tone
 scale), that property made this representation often use in musical signal
 analysis.
 The note A4, witch correspond to the frequency 440Hz is defined by the
 index 69 in the MIDI scale, by using the relation above, we fit the frequency
 scale to the MIDI musical one:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
midi(f)=69+12log_{2}\left(\frac{f}{440}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/cqtIHT.png
	scale 50
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Constant Q Transform (magnitude of the output of constant-Q filters) of
 the phrase 'we will have to watch our chances'.
 darker regions are more energetic.
 The Time/Frequency resolution depends on the frequency.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The advantage of CQT is that it is an invertible representation.
 The problem is that to keep the property of invertibility, the temporal
 step between two analyzed frames have to be smaller than the frame of the
 higher frequency (which can be very small, about 1millisecond for a frequency
 of 16kHz).
 This led to high cost in calculation.
\end_layout

\begin_layout Subsection
Cochleograms
\end_layout

\begin_layout Standard
The auditory system is thought to contain an array of over-lapping band-pass
 filters known as ‘auditory filters’.
 They occur along the basilar membrane and increase the frequency selectivity
 of the cochlea and therefore the listener’s discrimination between different
 sounds.
 The basiliar membrane is a part of the cochlea, and Cochleograms model
 the transformation made by these 'auditory models'.
 This transformation is mainly similar that the one use for the CQT, but
 using a real auditory response filter as the filter banks.
 The main difference between the CQT filter and those are there non-symmetricaln
ess of each filters.
 A auditory filter centered in the frequency 
\begin_inset Formula $f_{c}$
\end_inset

 is writing in the time domain as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
gt(t)=at^{(n-1)}exp\left(-2\pi bt\right)cos\left(2\pi f_{c}t+\phi\right)
\]

\end_inset


\end_layout

\begin_layout Standard
it is basically a cosine widowed by a non-symmetric widows that is the product
 of a power term and a decreasing exponential.
 The parameters of each filters mainly control the duration end therefore
 the bandwidth.
 In this study we used the same set of coefficients filter as in existing
 software (i.e the NSL toolbox).
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/cochleoPP.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Cochleogram (absolute value) of the phrase 'we will have to watch our chances'.
 darker regions are more energetic.
 The frequency scale is logaithmic and the Time/Frequency resolution is
 frequency dependent.
 low and high frequencies are lowered.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Cochleogram is the representation in Time/Frequency of the output of
 the magnitude of auditory filters.
 We can see in the next figure that they emphasize the magnitude over the
 frequency spectrum according to the human sensivity of tones.
 A nice introduction can be found in []...
\end_layout

\begin_layout Section
Scale-Space Representations
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
laure
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Wavelet-based transform
\end_layout

\begin_layout Standard
As we seen in the previous part, the resolution of time and frequency in
 a STFT representation obey to a firm compromise established before the
 analyze of the audio signal.
 In order to get a good resolution in time we need to use sharp windows
 that will affect the resolution of frequencies.
 The inverse is true, a good resolution in frequencies imply a long analyzed
 window decreasing the time resolution.
 But having a good resolution for the both of them is not possible, this
 property is related to the Heisenberg uncertainty principle.
 Somehow the wavelet were developed to resolve this problem.
 
\end_layout

\begin_layout Standard
The wavelet analyze was introduced by J.
 Morlet.
 It is not based on a representation of frequencies over time, but in transitory
 component present in the signal.
 In this idea, the wavelet transform decompose the signal in different scaled
 and translated versions of the mother wavelet.
 The mother wavelet is a function 
\begin_inset Formula $\psi$
\end_inset

 
\begin_inset Formula $\in L\mathbf{^{2}(\mathrm{\mathbb{R}})}$
\end_inset

, zero mean, normalized, centered in 
\begin_inset Formula $t=0$
\end_inset

, the shape is adapted on what we want to analyze.
 In audio signal we often use a windowed sinusoid.
\end_layout

\begin_layout Standard
A set of Frequency/Time atoms, are obtained by a scaling 
\begin_inset Formula $s$
\end_inset

, and a translation 
\begin_inset Formula $u$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\psi_{u,s}(t)=\frac{1}{\sqrt{s}}\psi\left(\frac{t-u}{s}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The weight of each of these scaled and translated version of the mother
 wavelet form the wavelet transform of the signal.
 It is a function of two variables, time and scale and give an alternative
 representation on 
\begin_inset Formula $f_{t}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Wf(u,s)=\langle f,\psi_{u,s}\rangle=\int_{-\infty}^{+\infty}f(t)\frac{1}{\sqrt{s}}\psi^{*}\left(\frac{t-u}{s}\right)dt
\]

\end_inset


\end_layout

\begin_layout Standard
because of the infinite sum this representation is very redundant.
 To avoid this we use discrete time and scale variables.
 Choosing 
\begin_inset Formula $k$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

, the discrete variables 
\begin_inset Formula $s=2^{j}$
\end_inset

 and 
\begin_inset Formula $u=k2^{j}$
\end_inset

, we can find a mother wavelet 
\begin_inset Formula $\psi(t)$
\end_inset

 such that the wavelet set form a orthonormal basis of the function in 
\begin_inset Formula $\mathcal{C^{\mathrm{2}}}$
\end_inset

.
\end_layout

\begin_layout Standard
If the input is a two dimensional data the wavelet basis over the continuous
 domain is the union of translating and dilating three mother wavelet functions
 
\begin_inset Formula $\left\{ \psi^{V},\psi^{H},\psi^{D}\right\} $
\end_inset

.
\end_layout

\begin_layout Standard
Each wavelet atom is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\psi_{k,j,n}(t)=\psi_{k,j}^{n}(t)==\frac{1}{\sqrt{2^{j}}}\psi^{n}\left(\frac{t-k2^{j}}{2^{j}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $s=2^{j}$
\end_inset

 , and the translation is 
\begin_inset Formula $u=2^{j}(k_{1},k_{2})$
\end_inset

, the computation do all the inner products .
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/lenaWavelet.eps
	scale 40
	BoundingBox -150bp 60bp 200bp 600bp
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Wavelet transform of an image, each plot can be understand as output of
 an inner product with a specific scaled, translated wavelet.
 They are tree different mother wavelets, 
\begin_inset Formula $\left\{ \psi^{V},\psi^{H},\psi^{D}\right\} $
\end_inset

 to form an orthogonal basis, respectively vertical, horizontal and diagonal.
 From the bottom right to the top left, the output of inner products with
 signal and scaled wavelet are ranked from the broadest scale to the sharpest.
 We observed that the representation with broad scaled wavelet show blurred
 contour of discontinuty.
 This representation is obtained by using the Toolbox image.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A mother wavelet with 
\begin_inset Formula $n$
\end_inset

 vanishing moments is the n-derivative of a function 
\begin_inset Formula $\theta$
\end_inset

.
 This means that the wavelet transform is a multi scale differential operator.
 The local regularity is then characterized by decreasing wavelets coefficients
 and local irregularity is emphasize by local maxima coefficients small
 scale.
\end_layout

\begin_layout Subsection
Corticograms
\end_layout

\begin_layout Standard
The primary auditory cortex is the part of the brain responsible of the
 understanding and segregation of equally tuned sound with temporal structure
 dissimilarity.
 After the cochlea processing the sound perceived are ordered along the
 tonotopic axis, witch means that they are projected according the cochlea
 shape, then ranking according their wavelength in particular area of brain.
 
\end_layout

\begin_layout Standard
Then the primary cortex analyzed the spectro-temporal content of the sound
 using layers of neuron.
 Those neurons, act as bank of filters, centered in each frequencies of
 the tonotopic axis.
 Each filter is tuned at a specific rate (temporal modulation in Hertz)
 and scale (frequency modulation in cycle/octave).
 Those actions can be approximately seen as a bank of 2D wavelet transform.
 
\end_layout

\begin_layout Standard
The characteristic function of each neuron are the STRF (spectro-temporal
 response field), showing the exhibiting and inhibitory fields in frequencies
 and time.
 The spectro-temporal variations of theses field are formed by 
\shape italic
ripples 
\shape default
(sound with a spectral pattern that have a sinusoidal shape along the logarithmi
c frequency axis).
 The mathematical model of the STRF is shown below:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
STRF=h_{IRT}(t)\star h_{IRS}(x)
\]

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $ $
\end_inset


\begin_inset Formula $h_{IRT}(t)$
\end_inset

 and 
\begin_inset Formula $h_{IRS}(x)$
\end_inset

 are two ripples parametrised by the characteristics of a specific neuron.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{IRT}(t,w,\theta)=h_{t}(t;w)cos\theta+\hat{h_{t}}(t;w)sin\theta
\]

\end_inset

where 
\begin_inset Formula $w$
\end_inset

 and
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\Omega$
\end_inset

 are the rates and scales, and 
\begin_inset Formula $\phi$
\end_inset

, 
\begin_inset Formula $\theta$
\end_inset

 are the characteristics phases of asymmetry.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
r\pm(t,f;w,\Omega;\theta,\phi)=z(t,f)\star_{t,f}STRF\pm(t,f;w,\Omega;\theta,\phi)
\]

\end_inset


\end_layout

\begin_layout Standard
r is the response of each Cochleograms convolued in time and frequency by
 a bank of STRF.
 We can see the Corticogram as a repeated Cochleogram viewed at different
 resolution, or as a bank of different spectral and temporal modulation
 filters with different tuning (from narrowband to broadband).
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/cortico1.png
	BoundingBox 0bp 20bp 432bp 288bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Corticograms visualization as a matrix of time-frequency representations.
 Each of the plots can be understood as a cochleogram filtered in 2D (rates
 and sclaes).
 Filter frequency are controlled by the scale and the rate parameters.
 In the top left pannel we see a represation with broadband filters in rates
 and scales.
 In bottom right we see a represention with sharpband filter of rate and
 scale, somehow representing the high frequencies of the 'wavelet transform'
 and is closed to the cochleogram.
 The botom right and top left are representation with sharp modulation in
 frequencies and time respectivelly.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Corticogram is a 4D representation indexed by scale/rate/time/frequency
 matrix.
 As such it can be figured as a set of matrix of Time/Frequency representation.
 interested reader can look a the paper ...
 into detail for better understanding of the computational detail of Corticogram
s.
 The implementation here is provided by the NSL toolbox.
\end_layout

\begin_layout Subsection
Quorticograms
\end_layout

\begin_layout Standard
As the CQT offer better performances in computation time and is invertible,
 we simplified the Corticogram by replacing the input Cochleogram by a CQT.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/cortico2.png
	BoundingBox 0bp 20bp 432bp 288bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Quorticograms visualization as a matrix of time-frequency representations.
 Each of the plots can be understood as a constant Q transform filtered
 in 2D (rates and sclaes).
 Filter frequency are controlled by the scale and the rate parameters.
 In the top left pannel we see a represation with broadband filters in rates
 and scales.
 In bottom right we see a represention with sharpband filter of rate and
 scale, somehow representing the high frequencies of the 'wavelet transform'
 and is closed to the CQT.
 The botom right and top left are representation with sharp modulation in
 frequencies and time respectivelly.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Other Representations
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
manu
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
SineWave Speech
\end_layout

\begin_layout Subsection
Feature transforms
\end_layout

\begin_layout Chapter
Measuring similarities between sounds sketches using a Fingerprinting approach
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Manu
\end_layout

\end_inset


\end_layout

\begin_layout Section
Ideas and concepts
\end_layout

\begin_layout Subsection
The evaluation problem
\end_layout

\begin_layout Subsection
Using Fingerprint as a proxy measure
\end_layout

\begin_layout Section
A fingerprinting framework
\end_layout

\begin_layout Subsection
Problem
\end_layout

\begin_layout Subsection
Architecture
\end_layout

\begin_layout Section
Generalization
\end_layout

\begin_layout Subsection
A unifying model
\end_layout

\begin_layout Subsection
A hybrid approach
\end_layout

\begin_layout Section
Distances in the fingerprint domain
\end_layout

\begin_layout Chapter
Recents experiments
\end_layout

\begin_layout Section
Results on the Constant-Q Transform in computational simulations
\end_layout

\begin_layout Standard
We tested the recognition rate of tree differents sounds representations,
 STFT, CQT and Cochleograms of musical intercept in musical database using
 fingerprint methods.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/results_Laure_CQT.pdf
	scale 30
	BoundingBox -400bp 0bp 430bp 441bp
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout

\lang french
Results on identifcation task over tree differents models of sound representatio
n (STFT, CQT, Cochleogram), on the left: recognition rate of the tree representa
tions over the added white noise, on the rigth: computation time over the
 size of the database.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
From psycho-physical experiments to computational simulations
\end_layout

\begin_layout Subsection
psycho-physical experiments
\end_layout

\begin_layout Standard
In the paper []...
 Suied & Drémeau 2013 perform two different experiments to test the ability
 of listener to recognize sketches.
 The first experiment test the overall recognition process of human listener,
 using sketches from difference psychoacoustics models of the sound (Cochleogram
/Corticogram).
 The second experience evaluate the processing of sketches, comparing the
 understanding of human listner for two different sparse method (IHT/PP).
\end_layout

\begin_layout Enumerate
The IHT (Iterative Hard Thresholding) algorithm selecting iteratively a
 set of sparse features, by doing a threshold.
 The stop criteria is the precision of reconstruction.
\end_layout

\begin_layout Enumerate
The PP (Peaks Picking) algorithm choose the local extreme values.
\end_layout

\begin_layout Standard
The data base consisted of the recorded 4 nonverbal emotion (anger, disgust,
 happiness and sadness) interjection (on the french vowel 
\begin_inset Formula $/a/$
\end_inset

) produced by 10 different actors.
 The results are illustrated by the two figure below.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/FigureSuiedDremeau1.pdf
	BoundingBox 0bp 570bp 595bp 760bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Results of the experiment 1: Recognition performance of the sketches sounds
 corresponding to two different auditory models.
 With an without noise the auditory spectogram (cochleogram) outperform
 the score of the corticogram, but not for noised signal with 1000 features/seco
nd.
 Two limits are sets: the lower one is the chance level (dotted line) and
 the upper one (black line) is the average recognition of original sound.
\end_layout

\end_inset


\end_layout

\end_inset

The first experiment show that the recognition on Cochleograms sketches
 outperform the one in Corticogram sketches.
 This is surprising as the Corticogram carry more information, and according
 to the study made in [timbre] this additional information is consequent
 for algorithm in classification of musical timbre.
 There are two hypothesis on this:
\end_layout

\begin_layout Enumerate
The sounds are too shorts (1s) to see the effects of the modulations filters.
 
\end_layout

\begin_layout Enumerate
This information help algorithm by mimicking the brain understanding of
 sound, but it can be to redundant for the human listeners, then the sparse
 reconstruction of sounds loose features in layers witch don't help the
 auditory recognition of a sound.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/FigureSuiedDremeau2.pdf
	BoundingBox 0bp 570bp 595bp 760bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Results of the experiment 2: Recognition performance of the sketches sounds
 (only the Cochleogram) corresponding to two differents sparse models.
 The PP algorithm outcast the performance of the IHT (Iterative Hard Thresholdin
g) algorithm, even with noise, but not for noised signal witch 1000 sparses
 features/second.
 Two limits are set: the lower one is the chance level (dotted line) and
 the upper one (black line) is the average recognition of original sound.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The second experiment show that the PP algorithm outperforms the IHT algorithms.
 This can be due to the fact that even if IHT performs a better reconstruction
 of the sound it cover a smaller range of features scale that PP algorithm.
\end_layout

\begin_layout Standard
In both experiences we see a surprising change of recognition results in
 signal with noise reconstructed with 1000 features.
 
\end_layout

\begin_layout Enumerate
Cochleogram/Corticogram: Corticogram excluded noise in layers with the non-impor
tant informations (could be also use for de-noising task: see [speech enhancemen
t using spectr...
 shamma]) then outperform Cochleograms in noise.
\end_layout

\begin_layout Enumerate
IHT/PP: IHT, by selecting better features to reconstruction, excluded noise
 witch is not the case of PP procedure selecting local maxima.
\end_layout

\begin_layout Subsection
Computational simulations
\end_layout

\begin_layout Standard
We did the same as experiment 2, but instead of listeners we test the ability
 of fingerprints in recognition (key overlap ratio) on CQT sketches:
\end_layout

\begin_layout Enumerate
Caracterized the recognition process of fingerprints on sketches.
\end_layout

\begin_layout Enumerate
Correlate the result of human psychoacoustic perception with a fingerprinting
 measure.
\end_layout

\begin_layout Standard
The results are shown below:
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/SparsityRobustness_k-5bar.png
	scale 50
	BoundingBox 0bp 0bp 432bp 280bp

\end_inset


\begin_inset Graphics
	filename figures/SparsityRobustness_k3bar.png
	scale 50
	BoundingBox 0bp 0bp 432bp 280bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Comparison of the key overlap ratio, in fingerprint task performed on sketches
 of CQT representation performed with PP and IHT sparses algorithmes.
 The figures show the results on signal reconstructed with wihte noise,
 in rigth the SNR is -5DB and in left the SNR is 3DB.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/NoiseRobustness_k200.pdf
	scale 50

\end_inset


\begin_inset Graphics
	filename figures/NoiseRobustness_k20.pdf
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Comparison of the key overlap ratio, in fingerprint task performed on sketches
 of CQT representation performed with PP and IHT sparses algorithmes, with
 a fixe number of features and over a bench of diffrents SNR in signal reconstru
ction.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Paragraph*
Conclusion: The results on IHT/PP algorithm is different that what we observed
 in the second experience:
\end_layout

\begin_layout Itemize
The IHT algorithm is far more robust to noise than PP, this is not true
 only if the signal is really clear and but if we have a clear signal with
 only few features then the PP algorithm is better, the IHT algorithm will
 peak really closed features.
\end_layout

\begin_layout Itemize
The fingerprint process is not easy correlated to the processing of human
 listener in recognition of sounds.
\end_layout

\begin_layout Itemize
The first experience raised unanswered question.
 Is the understanding of sketches related to the time of the signal excerpt?
 if not, how can we explain the decreasing result on experiment 1? Are the
 listening experiences similar in CQT representation than in Cochleograms?
\end_layout

\begin_layout Section
Sparsity-based sketches
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Mettre les comparaisons entre shazam et la même chose avec cqt/cochléo et
 IHT
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Put the comparison of Shazam research efficiency between different two dimension
al objects (CQT, Cochleogram and IHT).
\end_layout

\begin_layout Section
Invariant time Keys
\end_layout

\begin_layout Section
Sine-Wave speech
\end_layout

\begin_layout Enumerate
Classification of Sine Wave Speech.
\end_layout

\begin_layout Enumerate
Compare the understanding of current sentence and rare or grammatically
 correct but wrong meaning one.
\end_layout

\begin_layout Section
Finding invariants in 4 dimensional objects
\end_layout

\begin_layout Subsection
Looking for maximums
\end_layout

\begin_layout Enumerate
IHT
\end_layout

\begin_layout Enumerate
PP
\end_layout

\begin_layout Itemize
How drawing the representation.
\end_layout

\begin_layout Subsection
Research on variability
\end_layout

\begin_layout Enumerate
MPCA on time => could be related to build keys
\end_layout

\begin_layout Enumerate
Problem of time, different size: (1.
 Dynamic time wrapping, 2.
 Taking short intercepts)
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Ici mettre plein de figures : les corticogrammes sur les voix même phrase/locute
ur diff , même locuteur/phrase diff etc..
\end_layout

\end_inset


\end_layout

\begin_layout Section
What works and what don't
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Ici un récapitulatif de ce qui marche et de ce qui marche pas
\end_layout

\end_inset


\end_layout

\begin_layout Chapter*
Ongoing and future works
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Manu/Laure
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Achievements
\end_layout

\begin_layout Itemize
Plateform of testing
\end_layout

\begin_layout Itemize
Modeling of the fingerprint framework
\end_layout

\begin_layout Section*
Self-criticism
\end_layout

\begin_layout Itemize
How good is fingerprint as a proxy measure for similarities?
\end_layout

\begin_layout Section*
Link with next WP
\end_layout

\begin_layout Itemize
Our recommendations for real tests: SWS or Scale/Space blurred approximates
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/home/manu/Documents/Global-Fingerprint,/home/manu/Documents/Global-Fingerprint-sketch,/home/manu/Documents/Global-Perception,/home/manu/Documents/Global-Own,/home/manu/Documents/Global"
options "bibtotoc,abbrv"

\end_inset


\end_layout

\end_body
\end_document
